<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>snow-dev.com</title>
    <link href="https://snow-dev.com/atom.xml" rel="self" />
    <link href="https://snow-dev.com" />
    <id>https://snow-dev.com/atom.xml</id>
    <author>
        <name>Marcel Patzwahl</name>
        <email>marcel.patzwahl@posteo.de</email>
    </author>
    <updated>2018-12-26T00:00:00Z</updated>
    <entry>
    <title>VPC Peering with MongoDB Atlas and AWS in Terraform</title>
    <link href="https://snow-dev.com/posts/vpc-peering-with-mongodb-atlas-and-aws-in-terraform.html" />
    <id>https://snow-dev.com/posts/vpc-peering-with-mongodb-atlas-and-aws-in-terraform.html</id>
    <published>2018-12-26T00:00:00Z</published>
    <updated>2018-12-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2018-12-26
    </section>
    <hr class="section-head">
    <section>
        <p>Lately I was doing a lot of “Infrastructure as Code” (IaC) in terraform at work. There was one application, which needed a MongoDB as the primary database. Sadly there is no managed MongoDB service in AWS so far. So there were two initial options for me:</p>
<ul>
<li>Host a self managed MongoDB in an EC2 instance</li>
<li>Use Amazons DynamoDB</li>
</ul>
<p>The main goal of the move into the cloud was to get away from all the administration tasks and have everything managed by the cloud hosters, so we have more time to get our actual problems solved. That’s why option one wasn’t really something we wantet to do. Option two wasn’t satisfactorily either, because we would go deep into the AWS rabbit hole. We wouldn’t have the chance to test the application locally and always needed a connection to an actual DynamoDB instance.</p>
<p>Update 10.02.2019: Actually there is a real alternative now called AWS DocumentDB. I didn’t look into it so far, so I don’t feel qualified to give any opinion on DocumentDB. But based on the MongoDB CEO MongoDB <a href="https://www.mongodb.com/blog/post/documents-are-everywhere">Atlas still has it’s right to exist</a>.</p>
<p>Luckily there was a third option called <a href="https://www.mongodb.com/cloud/atlas">MongoDB Atlas</a>. This is MongoDB Inc’s own take at DaaS (Database as a Service). They instanciate a replica set of three or more instances on one of the most common cloud providers (AWS, Google Cloud Platform or Azure) for you. Additionally you get backups, auto scaling, alerts and many more features. MongoDB Atlas is also following an API first approach like AWS, so the creation of MongoDB resources can be automated. Sadly there is no support for MongoDB Atlas in Terraform so far. Luckily Akshay Karle already took care of this problem and <a href="https://github.com/akshaykarle/terraform-provider-mongodbatlas">wrote a third party plugin for Terraform</a>.</p>
<p>In this blog post we create an infrastructure setup which consists of 2 AWS VPCs. In the first VPC our application will be hosted. This application will be able to communicate with the MongoDB replica set, hosted in another VPC by Atlas. Because we will host our MongoDB cluster in the same region, we can benefit of VPC peering. This means, that the application and MongoDB can communicate directly via local IPs between the two VPCs and no traffic goes out to the internet and back into the other VPC. This is more secure (Because you don’t need to care about securing the connection, because it’s local anyway) and also a lot of faster than sending every request and response over the internet. We will code everything in Terraform, so we are able to create our whole infrastructure with one <em>terraform apply</em> and are done with it. So let’s get started. Here is a rough overview of the most important pieces:</p>
<p><img src="/images/vpc_overview.svg" alt="VPC Overview" title="VPC Overview" /></p>
<p>As you can see we have our 2 VPCs. The left AWS VPC will be avaible in the CIDR block 172.16.0.0/16. The right VPC is the one created by Mongo Atlas and will be available under 10.0.0.0/21. Both VPCs are connected via VPC-Peering. Also the CIDR block of the AWS VPC is whitelisted in MongoDB Atlas. On top we have a route table, to route traffic between the two VPCs and to the internet via an internet gateway.</p>
<p>The following guide will be threefold. In the first part we create the route table, internet gateway and AWS VPC with it’s subnet. In part two the MongoDB part will be build. In the third part we will deploy a small application inside of an EC2 instance, which is able to interact with the MongoDB. The whole code for this guide can be found <a href="https://github.com/snowiow/mongodbatlas-example-app">here</a>.</p>
<h1 id="part-1-the-aws-vpc">Part 1: The AWS VPC</h1>
<p>In this part we will be creating the left side of our overview diagram. So basically this part:</p>
<p><img src="/images/aws_vpc.svg" alt="VPC Overview" title="AWS VPC" /></p>
<p>In my example project I have created a subfolder called <code>terraform</code> where all the infrastructure code can be found. First of all we load the AWS Provider. This is done in the <code>main.tf</code>:</p>
<pre class="hcl"><code>provider &quot;aws&quot; {
  region  = &quot;eu-central-1&quot;
  version = &quot;1.54&quot;
}</code></pre>
<p>Next we create the actual VPC. This is done in the <code>vpc.tf</code> file:</p>
<pre class="hcl"><code>resource &quot;aws_vpc&quot; &quot;this&quot; {
  cidr_block = &quot;172.16.0.0/16&quot;

  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = {
    Name = &quot;vpc&quot;
  }
}</code></pre>
<p>As already stated in the beginning, we use the 172.16.0.0/16 CIDR block for the AWS VPC. We also enable DNS support and DNS hostnames inside of the VPC. With those two options we basically enable DNS discovery in the local VPC scope, which allows us to resolve the MongoDB cluster DNS to it’s private IP.</p>
<p>Now we create a subnet inside of the VPC:</p>
<pre class="hcl"><code>
resource &quot;aws_subnet&quot; &quot;this&quot; {
  cidr_block = &quot;176.16.0.0/16&quot;
  vpc_id     = &quot;${aws_vpc.this.id}&quot;

  map_public_ip_on_launch = true

  availability_zone = &quot;eu-central-1a&quot;

  tags = {
    Name = &quot;subnet1&quot;
  }
}</code></pre>
<p>Here we create one subnet, which takes all of the VPCs available addresses and is hosted in the availability zone eu-central-1a. Furthermore we want to give launched instances a public IP on startup to be able to download updates for the EC2 instance.</p>
<p>Next we put the internet gateway in front of the VPC, which is straight forward.</p>
<pre class="hcl"><code>resource &quot;aws_internet_gateway&quot; &quot;this&quot; {
  vpc_id = &quot;${aws_vpc.this.id}&quot;

  tags = {
    Name = &quot;internet-gateway&quot;
  }
}</code></pre>
<p>Finally we create the route table with a public route and associate our subnet to that route:</p>
<pre class="hcl"><code>resource &quot;aws_route_table&quot; &quot;this&quot; {
  vpc_id = &quot;${aws_vpc.this.id}&quot;

  tags = {
    Name = &quot;route-table-public&quot;
  }
}

resource &quot;aws_route&quot; &quot;this&quot; {
  route_table_id         = &quot;${aws_route_table.this.id}&quot;
  destination_cidr_block = &quot;0.0.0.0/0&quot;
  gateway_id             = &quot;${aws_internet_gateway.this.id}&quot;
}

resource &quot;aws_route_table_association&quot; &quot;this&quot; {
  route_table_id = &quot;${aws_route_table.this.id}&quot;
  subnet_id      = &quot;${aws_subnet.this.id}&quot;
}</code></pre>
<p>Basically what we are doing here is to allow to route traffic from our VPC to every address in the internet. This is mandatory, because we want to get responses from our web applications inside of the VPC.</p>
<p>That’s it for the first part. You are now able to run <code>terraform init &amp;&amp; terraform apply</code> to deploy the AWS VPC.</p>
<h1 id="part-2-mongodb-atlas">Part 2: MongoDB Atlas</h1>
<p>In this part we care about the right half of the diagram and create our MongoDB Cluster at Atlas, make a whitelist entry for our AWS VPC and create VPC Peering between the two VPCs:</p>
<p><img src="/images/mongodb_atlas.svg" alt="MongoDB Atlas" title="MongoDB Atlas" /></p>
<p>You can find the part 2 code in the <code>atlas.tf</code> file. We get started again, by adding a new provider to the <code>main.tf</code>:</p>
<pre class="hcl"><code>provider &quot;mongodbatlas&quot; {
  username = &quot;${var.username}&quot;
  api_key  = &quot;${var.api_key}&quot;
}</code></pre>
<p>To access your MongoDB Atlas account you need to pass your username and an API key. If you define them as variables like me, you can create a new file called <code>variables.tf</code> with the following content:</p>
<pre class="hcl"><code>variable &quot;username&quot; {
  type        = &quot;string&quot;
  description = &quot;The Username for the MongoDB Atlas Login&quot;
}

variable &quot;api_key&quot; {
  type        = &quot;string&quot;
  description = &quot;The API Key for the MongoDB Atlas Login&quot;
}</code></pre>
<p>this defines the variables used in the <code>main.tf</code> file. Next we create a <code>terraform.tfvars</code> in which we actually set the values of those variables:</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="dt">username </span><span class="ot">=</span><span class="st"> &quot;&lt;your_username&gt;&quot;</span>
<span class="dt">api_key </span><span class="ot">=</span><span class="st"> &quot;&lt;your_api_key&gt;&quot;</span></code></pre></div>
<p>Because we save trustworthy information in those variables, we don’t actually set them in a normal <code>*.tf</code> file. These files are checked into version control, so we don’t want to write those informations down in those files. Instead we use <code>*.tfvars</code> files, which aren’t checked into version control.</p>
<p>As said in the beginning, mongodb atlas isn’t supported by terraform officially. So we need to install the third party provider. To install the provider you need to have <a href="https://golang.org/">go</a> installed. With go installed you can get the package and symlink the executable to the plugin folder of terraform:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">go</span> get github.com/akshaykarle/terraform-provider-mongodbatlas
<span class="fu">ln</span> -s <span class="va">$GOPATH</span>/bin/terraform-provider-mongodbatlas \
      ~/.terraform.d/plugins/</code></pre></div>
<p>If you do a <code>terraform init</code> again, you are able to initialize the mongodbatlas provider as well.</p>
<p>With everything set up, we can start creating the MongoDB Atlas cluster. The first thing needed is a project (former known as groups). Projects are a sort of grouping to isolate different environments from each other or to configure different alert settings. For a full description head over to the <a href="https://docs.atlas.mongodb.com/tutorial/manage-projects/">official documentation</a>. We create a new file called <code>atlas.tf</code> for all our MongoDB Atlas resources. There we create a project first:</p>
<pre class="hcl"><code>resource &quot;mongodbatlas_project&quot; &quot;this&quot; {
  org_id = &quot;${var.org_id}&quot;
  name   = &quot;example-project&quot;
}</code></pre>
<p>To create a project resource we need an organisation id, which can be found in the settings tab:</p>
<p><img src="/images/mongodbatlas_organisation_id.png" alt="MongoDB Atlas Organisation ID" title="MongoDB Atlas Organisation ID" /></p>
<p>Because we use it as a variable in the <code>atlas.tf</code> file, we need to add it to our <code>terraform.tfvars</code></p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="dt">...</span>
<span class="dt">org_id </span><span class="ot">=</span><span class="st"> &quot;&lt;your-organisation-id&gt;&quot;</span></code></pre></div>
<p>and <code>variables.tf</code></p>
<pre class="hcl"><code>variable &quot;org_id&quot; {
  type        = &quot;string&quot;
  description = &quot;The organisation id of the mongodb Login&quot;
}</code></pre>
<p>The next thing we need is a container. The container is the network of the cloud provider. In the example of AWS it would create a VPC.</p>
<pre class="hcl"><code>resource &quot;mongodbatlas_container&quot; &quot;this&quot; {
  group            = &quot;${mongodbatlas_project.this.id}&quot;
  atlas_cidr_block = &quot;10.0.0.0/21&quot;
  provider_name    = &quot;AWS&quot;
  region           = &quot;EU_CENTRAL_1&quot;
}</code></pre>
<p>Pay attention to the region names, because they are <a href="https://docs.atlas.mongodb.com/reference/api/clusters-create-one/">different than in AWS</a>.</p>
<p>Now we can create the cluster:</p>
<pre class="hcl"><code>resource &quot;mongodbatlas_cluster&quot; &quot;this&quot; {
  name                  = &quot;example&quot;
  group                 = &quot;${mongodbatlas_project.this.id}&quot;
  mongodb_major_version = &quot;4.0&quot;
  provider_name         = &quot;AWS&quot;
  region                = &quot;EU_CENTRAL_1&quot;
  size                  = &quot;M10&quot;
  disk_gb_enabled       = true
  backup                = false
  depends_on            = [&quot;mongodbatlas_container.this&quot;]
}</code></pre>
<p>Here we create a MongoDB Cluster in Version 4.0 in AWS with the same region as the container. M10 is the smallest non sandbox size available. It has 2GB of RAM, 10 GB of storage and 0.2 vCPUs. With <code>disk_gb_enabled</code> we allow the cluster to automatically scale up. Lastly the cluster should be created explicitly after the container.</p>
<p>Now we create a database user:</p>
<pre class="hcl"><code>resource &quot;mongodbatlas_database_user&quot; &quot;this&quot; {
  username = &quot;application-user&quot;
  password = &quot;application-pw&quot;
  database = &quot;admin&quot;
  group    = &quot;${mongodbatlas_project.this.id}&quot;

  roles {
    name     = &quot;readWrite
    database = &quot;app&quot;
  }
}</code></pre>
<p>This user will later be used by the application to access the MongoDB. He gets a username, password and a will be authenticated in the <code>admin</code> database. Those information can also be exported to the <code>terraform.tfvars</code> file, but for this example application I keep those information hardcoded in the <code>atlas.tf</code> file. The <code>admin</code> database is the default value for MongoDB Atlas. The user gets rights to read and write to the <code>app</code> database.</p>
<p>Next thing we do, is establishing the VPC peering connection:</p>
<pre class="hcl"><code>resource &quot;mongodbatlas_vpc_peering_connection&quot; &quot;this&quot; {
  group                  = &quot;${mongodbatlas_project.this.id}&quot;
  aws_account_id         = &quot;${var.aws_account_id}&quot;
  vpc_id                 = &quot;${aws_vpc.this.id}&quot;
  route_table_cidr_block = &quot;${aws_vpc.this.cidr_block}&quot;
  container_id           = &quot;${mongodbatlas_container.this.id}&quot;
}

resource &quot;aws_vpc_peering_connection_accepter&quot; &quot;this&quot; {
  vpc_peering_connection_id = &quot;${mongodbatlas_vpc_peering_connection.this.connection_id}&quot;
  auto_accept               = true
}</code></pre>
<p>First we create the MongoDB Atlas peering connection. The connection needs most of the stuff, we created before, like the AWS VPC to peer to and the container of our MongoDB cluster. Here we use another variable for the AWS account in which the destination VPC for the peering lies. This variable will be created analogous to those, we created earlier. The second thing is an acceptor, which should auto accept the peering requests for peerings with the MongoDB VPC.</p>
<p>Now we can also create an entry in our route table for the new MongoDB Atlas VPC, which allows traffic to be routed between those two VPCs properly:</p>
<pre class="hcl"><code>resource &quot;aws_route&quot; &quot;this&quot; {
  route_table_id            = &quot;${data.aws_route_table.this.id}&quot;
  destination_cidr_block    = &quot;${mongodbatlas_container.this.atlas_cidr_block}&quot;
  vpc_peering_connection_id = &quot;${mongodbatlas_vpc_peering_connection.this.connection_id}&quot;
}</code></pre>
<p>The last thing we have to do, is whitelist the AWS VPC CIDR Block in MongoDB Atlas, so that services inside of the AWS VPC are allowed to access the cluster.</p>
<pre class="hcl"><code>resource &quot;mongodbatlas_ip_whitelist&quot; &quot;this&quot; {
  group      = &quot;${mongodbatlas_project.this.id}&quot;
  cidr_block = &quot;${data.aws_vpc.this.cidr_block}&quot;
  comment    = &quot;Whitelist for the AWS VPC&quot;
}</code></pre>
<p>With this in place we are now able to create our MongoDB Atlas cluster. Again you can execute <code>terraform apply</code> to see the results.</p>
<h1 id="part-3-deploying-the-app">Part 3: Deploying the app</h1>
<p>In the last part we keep it as simple as possible. We will create a single EC2 instance, which will be provisioned to install a docker container with a small PHP application. The important part here, is that we now can give the DSN (Data Source Name) of the MongoDB to the app as an environment variable and the app is able to work with the MongoDB without any further manual interventions.</p>
<p>In reality there is a lot more to running a scalable infrastructure, like load balancing, autoscaling groups, launch templates and logging to name a few. But covering these topics in this post would crush the scope of this article, which is already pretty long at this point.</p>
<p>So without further ado let’s get startet by creating a <code>ec2.tf</code> file. First of all we create an AMI</p>
<pre class="hcl"><code>data &quot;aws_ami&quot; &quot;amazon_linux&quot; {
  most_recent = true
  owners      = [&quot;amazon&quot;]

  filter {
    name   = &quot;name&quot;
    values = [&quot;amzn2-ami-hvm-2.0.20181024-x86_64-gp2&quot;]
  }
}</code></pre>
<p>This defines an AMI (Amazon Machine Image) which is basically the operating system, the ec2 instance will be started with.</p>
<p>In this EC2 instance we will run a docker container. I created a repository in amazons own ECR for my container image. So I add the repository as a data source:</p>
<pre class="hcl"><code>data &quot;aws_ecr_repository&quot; &quot;example_app&quot; {
  name = &quot;snowiow/example-app&quot;
}</code></pre>
<p>Now we create a small shell script, which will be executed as soon as the instance is started.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">echo</span> <span class="st">&quot;Update YUM&quot;</span>
<span class="fu">sudo</span> yum -y update

<span class="bu">echo</span> <span class="st">&quot;Install Docker&quot;</span>
<span class="fu">sudo</span> yum install -y docker

<span class="bu">echo</span> <span class="st">&quot;Start Docker&quot;</span>
<span class="fu">sudo</span> service docker start

<span class="bu">echo</span> <span class="st">&quot;Login to ECR (your Docker Registry)&quot;</span>
<span class="va">$(</span><span class="ex">aws</span> ecr get-login --no-include-email --region eu-central-1<span class="va">)</span>

<span class="bu">echo</span> <span class="st">&quot;Start docker container&quot;</span>
<span class="ex">docker</span> run \
  -p 80:80 \
  --env <span class="st">&quot;MONGO_DSN=</span><span class="va">${mongodb_dsn}</span><span class="st">&quot;</span> \
  --env <span class="st">&quot;MONGO_DB=app&quot;</span> \
  <span class="va">${container_img_url}</span></code></pre></div>
<p>Basically this installs docker, downloads the image from the container repository URL, where I uploaded it and executes it. As environment variables I give the container the DSN of the MongoDB cluster, the container repository URL and the database, which will always be called app, so it is hardcoded here. The DSN and repository URL values are interpolated, so we need a way to fill in the actual values. We do this by creating a template file as a data source in terraform:</p>
<pre class="hcl"><code>data &quot;template_file&quot; &quot;user_data&quot; {
  template = &quot;${file(&quot;user_data.sh&quot;)}&quot;

  vars {
    mongodb_dsn    = &quot;mongodb://${mongodbatlas_database_user.this.username}:${mongodbatlas_database_user.this.password}@${substr(mongodbatlas_cluster.this.mongo_uri_with_options, 10, -1)}&quot;
    docker_img_url = &quot;${data.aws_ecr_repository.example_app.repository_url}&quot;
  }
}</code></pre>
<p>Here we have to do some string manipulations to get the username and password in the DSN as well, otherwise the app wouldn’t be able to login to the cluster.</p>
<p>The last thing we need before creating our instances, is an IAM Role. The EC2 instance we launch will assume this role and will have the rights provided by this role. First of all we need a policy document, which says, that the EC2 instance is allowed to assume a role</p>
<pre class="hcl"><code>data &quot;aws_iam_policy_document&quot; &quot;assume&quot; {
  statement {
    sid     = &quot;AllowAssumeByEC2&quot;
    effect  = &quot;Allow&quot;
    actions = [&quot;sts:AssumeRole&quot;]

    principals {
      type        = &quot;Service&quot;
      identifiers = [&quot;ec2.amazonaws.com&quot;]
    }
  }
}</code></pre>
<p>Now we can create the role itself</p>
<pre class="hcl"><code>resource &quot;aws_iam_role&quot; &quot;example_app&quot; {
  name               = &quot;example-app-iam-role&quot;
  assume_role_policy = &quot;${data.aws_iam_policy_document.assume.json}&quot;
}</code></pre>
<p>Because our EC2 instance needs to download a Docker Image from the ECR, we need to give the right to the role first. Therefore we create another policy document:</p>
<pre class="hcl"><code>data &quot;aws_iam_policy_document&quot; &quot;ecr&quot; {
  statement {
    sid    = &quot;AllowECRAuthorization&quot;
    effect = &quot;Allow&quot;

    actions = [
      &quot;ecr:GetAuthorizationToken&quot;,
    ]

    resources = [&quot;*&quot;]
  }

  statement {
    sid    = &quot;AllowECRDownload&quot;
    effect = &quot;Allow&quot;

    actions = [
      &quot;ecr:GetDownloadUrlForLayer&quot;,
      &quot;ecr:BatchGetImage&quot;,
      &quot;ecr:BatchCheckLayerAvailability&quot;,
    ]

    resources = [&quot;${data.aws_ecr_repository.example_app.arn}&quot;]
  }
}</code></pre>
<p>This policy consists of two statements. The first one allows an action to authorize ourselfs with the ECR, which we do in the <code>user_data.sh</code> script with this statement:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="va">$(</span><span class="ex">aws</span> ecr get-login --no-include-email --region eu-central-1<span class="va">)</span></code></pre></div>
<p>As a resource <code>*</code> was chosen, because the <code>ecr:GetAuthorizationToken</code> action is global and can’t be restricted to a specific resource. The second statement allows the download of the image. Here we defined the ARN of the specific repository, we want to pull from, because we don’t want to allow our EC2 instance to pull from every repository we have in our account.</p>
<p>With this policy document, we can create an actual policy from it, which will be attached to our <code>example-app-role</code>:</p>
<pre class="hcl"><code>resource &quot;aws_iam_policy&quot; &quot;ecr&quot; {
  name        = &quot;ExampleAppECRAccess&quot;
  description = &quot;Gives right to get an ECR authorization token and pull images&quot;
  policy      = &quot;${data.aws_iam_policy_document.ecr.json}&quot;
}

resource &quot;aws_iam_role_policy_attachment&quot; &quot;ecr&quot; {
  role       = &quot;${aws_iam_role.example_app.name}&quot;
  policy_arn = &quot;${aws_iam_policy.ecr.arn}&quot;
}</code></pre>
<p>Because we can’t attach a role directly to an EC2 instance, we need an instance profile:</p>
<pre class="hcl"><code>resource &quot;aws_iam_instance_profile&quot; &quot;this&quot; {
  name = &quot;example-app-instance-profile&quot;
  role = &quot;${aws_iam_role.example_app.name}&quot;
}</code></pre>
<p>Finally we create the EC2 instance itself and output the IP address, where it is reachable afterwards. We also need a security group for the instance, which basically tells who will be able to access the instance and to who the instance is allowed to respond to. In this example we allow traffic from any IP over port 80, because this is the port where the website is hosted:</p>
<pre class="hcl"><code>resource &quot;aws_security_group&quot; &quot;this&quot; {
  name   = &quot;sg&quot;
  vpc_id = &quot;${aws_vpc.this.id}&quot;

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = &quot;tcp&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = &quot;-1&quot;
    cidr_blocks = [&quot;0.0.0.0/0&quot;]
  }
}

resource &quot;aws_instance&quot; &quot;this&quot; {
  ami                  = &quot;${data.aws_ami.amazon_linux.id}&quot;
  instance_type        = &quot;t2.micro&quot;
  subnet_id            = &quot;${aws_subnet.this.id}&quot;
  user_data            = &quot;${data.template_file.user_data.rendered}&quot;
  iam_instance_profile = &quot;${aws_iam_instance_profile.this.name}&quot;
  security_groups      = [&quot;${aws_security_group.this.id}&quot;]
}

output &quot;example_app&quot; {
  value = &quot;${aws_instance.this.public_ip}&quot;
}</code></pre>
<p>This is it! If you execute <code>terraform apply</code> again, you will see the public IP of the EC2 instance. To see if the connection to the MongoDB is working we can play around with the example application.</p>
<p>The example application is a small website with two routes. Both use GET parameters. The first route looks like this:</p>
<pre><code>/insert/{firstname}/{lastname}</code></pre>
<p>This route will insert a user with a first and lastname into the MongoDB. For the example of will willson we combine the returned IP of the terraform script with the route like this</p>
<pre><code>&lt;ec2ip&gt;/insert/will/willson</code></pre>
<p>the response would look like this:</p>
<p><img src="/images/insert_will_willson.png" alt="Insert Will Willson" title="Insert Will Willson" /></p>
<p>To really see if the user was inserted into MongoDB, we use the second route, which looks like this:</p>
<pre><code>/{lastname}</code></pre>
<p>Basically if we insert the lastname as the only part of the route, the example application searches for users with this lastname and will print them. For the example of willson the URL would look like this:</p>
<pre><code>&lt;ec2ip&gt;/willson</code></pre>
<p>and we get this response</p>
<p><img src="/images/will_willson_is_here.png" alt="Will Willson is here" title="Will Willson is here" /></p>
<p>This application is pretty basic but works as a proof of concept of our infrastructure.</p>
<p>So there you have it. A VPC peering connection between MongoDB Atlas and our own AWS VPC, which is applicable in a single command, thanks to terraform. I created this post because there are many useful resources scattered around about this topic, but there is no single resource which combines them all together. So I hope this is of help for anybody who is trying to achieve something similar.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Build your own Git Server with a Raspberry Pi</title>
    <link href="https://snow-dev.com/posts/build-your-own-git-server-with-a-raspberry-pi.html" />
    <id>https://snow-dev.com/posts/build-your-own-git-server-with-a-raspberry-pi.html</id>
    <published>2017-06-03T00:00:00Z</published>
    <updated>2017-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2017-06-03
    </section>
    <hr class="section-head">
    <section>
        <p>In this post I want to go into a topic, which I did a few months ago. My goal was to get some of my data away from big cloud hosting platforms back into my own control. The initial spark was a news about a french artist, who had all his pictures on googles platform blogger. His blog was deleted out of no reason and his whole work was lost. You can read the whole story <a href="http://fusion.net/story/325231/google-deletes-dennis-cooper-blog/">here</a>. Scared of a similar scenario, I decided to setup my own cloud with seafile and my own Git server. In this post I will cover how to put up a simple Git server with a basic web fronted to view the repositories. I still use GitHub pretty extensively but all my little and non private projects go onto my own Git server now. First things first, we need some hardware to get started:</p>
<ul>
<li>A Raspberry Pi 3 Model B (older models should be sufficient too, but the newer the more performance you got at your hand)</li>
<li>5V Micro USB Plug</li>
<li>A Micro SD Card (the bigger, the better)</li>
<li>A Raspberry PI 3 Case</li>
<li>Another Computer to store an OS image on the SD Card (This guide shows the Linux way, but it should also be possible on Windows and OSX)</li>
<li>An ethernet cable to initially connect your Raspberry Pi to your router</li>
</ul>
<p>I also bought an external hard drive where all my Git repositories and cloud stuff is stored, but you can also buy a big SD-card and store the repositories on it directly. In this guide I will go about the default SD Card way. If you want to use an external hard drive, you need to format it to sda4 for example and mount it to the point, where you want to have it. All your Git repository directories should go there and the mount point will be your Git root. Otherwise the procedure is the same as given in this guide.</p>
<p>One last thing on the notations in this post. Because we need to execute many commands from the command line, I will use a short notion for which commands have to be executed as which user. If a line starts with the <strong>$</strong> sign, the command is executable by a normal user. If you see a <strong>#</strong> in the beginning, you need to either execute the command with the <em>sudo</em> utility or be logged in as the root user.</p>
<h1 id="installing-the-os-on-the-sd-card">Installing the OS on the SD-Card</h1>
<p>I decided to use Arch Linux ARM for the Raspberry Pi, but you are free to use anything you want here. The reason why I chose Arch is because it’s a very minimal distribution. That said it only installs relevant software and from there you are free to go. A warning up front: We will never get to see a GUI, like in Raspbian or another Raspberry Pi distribution. On the plus side of things is, you will have much more RAM and processor performance for the software that really matters. My Raspberry Pi with Seafile and hosting the Git site on an nginx server is using around 200Mb/1GB of RAM and about 2% of one of the 4 processors on average. So there is plenty of stuff my Raspberry could do as well, without getting overwhelmed.</p>
<p>But let’s get back to the installation: First tricky thing here is to use the ARM7 Version. Even through the Raspberry Pi is listed as ARM8 I got huge problems to get my wireless up and running. So go and get the Arch Linux ARM7 <a href="http://os.archlinuxarm.org/os/ArchLinuxARM-rpi-2-latest.tar.gz">here</a>. Afterwards you need to follow the installation instructions <a href="https://archlinuxarm.org/platforms/armv7/broadcom/raspberry-pi-2">here</a>.</p>
<h1 id="configuring-the-os">Configuring the OS</h1>
<p>By now you should have installed Arch Linux ARM on the SD-Card, plugged it in and you should be logged into your Raspberry Pi (Don’t forget to connect your Raspberry Pi to your router if you want to connect via SSH). There were still some steps I needed to do to get started with my main project. Here is a short list:</p>
<ul>
<li><a href="https://wiki.archlinux.org/index.php/Installation_guide#Set_the_keyboard_layout">Set your keyboard layout</a></li>
<li><a href="https://wiki.archlinux.org/index.php/Wireless_network_configuration#Manual_setup">Setup the wifi connection</a></li>
<li><a href="https://wiki.archlinux.org/index.php/Installation_guide#Time_zone">Set your timezone, locale and hostname</a></li>
</ul>
<h1 id="setting-up-git">Setting up Git</h1>
<p>Now we can get started with our real project. First we need to install Git:</p>
<pre><code># pacman -S git</code></pre>
<p>Next we create a new Git user, who will be responsible for the repositories:</p>
<pre><code># adduser -m -g git -s /bin/bash git</code></pre>
<p>The <strong>-m</strong> flag says that we want to create a user directory in <strong>/home</strong>. <strong>-g</strong> is the default group of our user and <strong>-s</strong> is the default shell of the user. We need to be able to do stuff as the Git user, that’s why he gets a shell. That’s it. Now you are basically ready to do Git stuff with your Raspberry Pi.</p>
<h1 id="create-a-new-git-repository">Create a new Git Repository</h1>
<p>The next thing we want to do is create a new Git repository. Before we do anything Git related, we want to suspend ourselves as the Git user, like this:</p>
<pre><code># su git</code></pre>
<p>Now we are the Git user and can do stuff in his name. First we need a place, where we want to place our repositories. A good place is the home directory of the Git user, but it can be anywhere else, where the Git user has write access. Now we create a new repository called <em>new-project</em>:</p>
<pre><code>$ mkdir /home/git/new-project.git &amp;&amp; cd /home/git/new-project.git &amp;&amp; git init --bare</code></pre>
<p>First we create a new directory with a <em>.git</em> ending. You don’t need the ending, but it’s a best practice, to let server side repositories end with <em>.git</em>. Afterwards we go into that directory and initiate it as a Git repository. The <em>bare</em> argument is somewhat optional again, but also a best practice. It just means this Git repository doesn’t have a working directory. The working directory is where you put your files. On the same level is a <em>.git</em> directory with the history and other things in it. The <em>bare</em> argument now says that you don’t need the working directory and the main directory can become the <em>.git</em> directory. So overall you can remember to use the <em>bare</em> argument on the server side of a repository and not on the client side. # Clone your repo Now we want to clone our newly created repository from the server. You should already  know the ip of your Raspberry, when you’ve set it up via ssh. If you don’t know the IP yet, you can run the command ifconfig as root, which should give you something like this as an output:</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="co">#ifconfig</span>
<span class="dt">eth0: flags</span><span class="ot">=</span><span class="dv">4099</span><span class="st">&lt;UP,BROADCAST,MULTICAST&gt;  mtu </span><span class="dv">1500</span>
<span class="dt">        ether b8:27:eb:8c:97:af  txqueuelen 1000  (Ethernet)</span>
<span class="dt">        RX packets 0  bytes 0 (0.0 B)</span>
<span class="dt">        RX errors 0  dropped 0  overruns 0  frame 0</span>
<span class="dt">        TX packets 0  bytes 0 (0.0 B)</span>
<span class="dt">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span>

<span class="dt">lo: flags</span><span class="ot">=</span><span class="dv">73</span><span class="st">&lt;UP,LOOPBACK,RUNNING&gt;  mtu </span><span class="dv">65536</span>
<span class="dt">        inet 127.0.0.1  netmask 255.0.0.0</span>
<span class="dt">        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;</span>
<span class="dt">        loop  txqueuelen 1  (Local Loopback)</span>
<span class="dt">        RX packets 1004803  bytes 352750188 (336.4 MiB)</span>
<span class="dt">        RX errors 0  dropped 0  overruns 0  frame 0</span>
<span class="dt">        TX packets 1004803  bytes 352750188 (336.4 MiB)</span>
<span class="dt">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span>

<span class="dt">wlan0: flags</span><span class="ot">=</span><span class="dv">4163</span><span class="st">&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu </span><span class="dv">1500</span>
<span class="dt">        inet 192.168.178.48  netmask 255.255.255.0  broadcast 192.168.178.255</span>
<span class="dt">        inet6 fe80::ba27:ebff:fed9:c2fa  prefixlen 64  scopeid 0x20&lt;link&gt;</span>
<span class="dt">        ether b8:27:eb:d9:c2:fa  txqueuelen 1000  (Ethernet)</span>
<span class="dt">        RX packets 1727438  bytes 275330489 (262.5 MiB)</span>
<span class="dt">        RX errors 0  dropped 1561  overruns 0  frame 0</span>
<span class="dt">        TX packets 4660814  bytes 2524959215 (2.3 GiB)</span>
<span class="dt">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span></code></pre></div>
<p>As you can see in the output, I am connected via wifi. So the IP address of interest is under <em>inet</em> in the <em>wlan0</em> block. If you are connected via cable, there should be an <em>inet</em> entry in the <em>eth0</em> block. Now we know where to clone the repository from like this:</p>
<pre><code>$ git clone git@&lt;your-inet-entry-here&gt;:/home/git/new-project.git</code></pre>
<p>In my case the command would look like this:</p>
<pre><code>$ git clone git@192.168.178.48:/home/git/new-project.git</code></pre>
<h1 id="push-your-first-change">Push your first change</h1>
<p>Let’s add a file with</p>
<pre><code>$ touch test.txt</code></pre>
<p>Now you should have some changes, which you can check with</p>
<pre><code>$ git status</code></pre>
<p>Now we do our first commit and add the test file to our commit.</p>
<pre><code>$ git commit -a -m &quot;added test file&quot; &amp;&amp; git push</code></pre>
<p>Congratulations! You first commit has landed on the server.</p>
<h1 id="initiate-an-existing-project-as-a-raspberry-git-repository">Initiate an existing project as a Raspberry Git repository</h1>
<p>We pretty much covered everything which you need to know to work with your new Git server. But there is one last common use case, which I want to present to you. What if you were already working on a project and want to sync it with the server? First you have to switch into that directory and make it a Git repository like this.</p>
<pre><code>$ cd /path/to/existing-project &amp;&amp; git init</code></pre>
<p>Same thing on your Raspberry Pi. Create the directory with a <em>.git</em> ending and init it with the <em>bare</em> argument (remember to do this as the Git user)</p>
<pre><code>$ cd /home/git/existing-project.git &amp;&amp; cd /home/git/existing-project.git &amp;&amp; git init --bare</code></pre>
<p>Afterwards your project files can be added to an initial commit like this (this happens on your work station again)</p>
<pre><code>$ git commit -a -m &quot;my first commit&quot;</code></pre>
<p>So far there is nothing special. But now we add our Raspberry Pi as the remote server</p>
<pre><code>$ git remote add origin git@&lt;your-inet-entry-here&gt;:/home/git/existing-project.git</code></pre>
<p>Again in my case the command would look like this and you have to change it to your case accordingly</p>
<pre><code>$ git remote add origin git@192.16.178.48:/home/git/existing-project.git</code></pre>
<p>Now you can push your fist changes and set the Raspberry Pi as the default origin like this</p>
<pre><code>$ git push --set-upstream origin master</code></pre>
<p>You are also able to name <em>origin</em> anything you want. <em>Origin</em> is just a convention which is used for the default upstream. This was the main part, which should get you up to speed with Git on a Raspberry Pi. In the next chapter I want to show you, how to set up a simplistic Git web frontend to watch your repositories, commits and diffs in the web browser.</p>
<h1 id="create-a-website-to-view-your-repositories">Create a Website to view your repositories</h1>
<p>The feature we are are using is the built in gitweb. It’s a minimal web frontend to view your code and you should already have seen sites like this here and there. For example the project overview of my dotfiles repository looks like this:</p>
<p><img src="/images/gitweb_example.png" alt="Gitweb" title="Gitweb" /></p>
<p>First of all we need a running webserver, to host our Git site. We are going for nginx in this tutorial, but it’s also possible to use <a href="https://wiki.archlinux.org/index.php/gitweb">apache</a>. To install nginx, we run</p>
<pre><code># pacman -S nginx-mainline</code></pre>
<p>Afterwards we also need to install perl-cgi</p>
<pre><code># pacman -S perl-cgi</code></pre>
<p>Now we start the nginx service via systemd</p>
<pre><code># systemctl start nginx</code></pre>
<p>You can check if the nginx server is running by looking up the ip address of your Raspberry Pi in your browser. In my case this would be navigating to <em>192.168.178.48</em>. You should see a success message, that the nginx server is running. Because gitweb comes preinstalled with Git, we can directly go into activating the gitweb cgi script. Therefor we need to edit the <em>/etc/nginx/nginx.conf</em></p>
<pre class="default"><code>server {
    listen       80;
    server_name  localhost;

    #charset koi8-r;

    #access_log  logs/host.access.log  main;


    #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    location /gitweb.cgi {
            include fastcgi_params;
            gzip off;
            fastcgi_param   SCRIPT_FILENAME  /usr/share/gitweb/gitweb.cgi;
            fastcgi_param   GITWEB_CONFIG  /etc/gitweb.conf;
            fastcgi_pass    unix:/var/run/fcgiwrap.sock;
    }

    location / {
        root /usr/share/gitweb;
        index gitweb.cgi;
    }
    ...
}</code></pre>
<p>As you can see in the code snippet, you need to add the gitweb.cgi location into the server entity and tell nginx where to find the fastcgi_params and pass. You also need to override the default location to be gitweb.cgi. All changes you need to do, are highlighted in yellow. Now we need to install fcgiwrap. This is a cgi server, which runs our gitweb cgi app.</p>
<pre><code># pacman -S fcgiwrap</code></pre>
<p>Then we need to add a service config for fcgiwrap to be able to start it via systemctl. Create the following file _/usr/lib/systemd/system/fcgiwrap.service _with this content</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="kw">[Unit]</span>
<span class="dt">Description</span><span class="ot">=</span><span class="st">Simple server for running CGI applications over FastCGI</span>
<span class="dt">After</span><span class="ot">=</span><span class="st">syslog.target network.target</span>

<span class="kw">[Service]</span>
<span class="dt">Type</span><span class="ot">=</span><span class="st">forking</span>
<span class="dt">Restart</span><span class="ot">=</span><span class="kw">on</span><span class="st">-abort</span>
<span class="dt">PIDFile</span><span class="ot">=</span><span class="st">/var/run/fcgiwrap.pid</span>
<span class="dt">ExecStart</span><span class="ot">=</span><span class="st">/usr/bin/spawn-fcgi -s /var/run/fcgiwrap.sock -P /var/run/fcgiwrap.pid -u http -g http -- /usr/sbin/fcgiwrap</span>
<span class="dt">ExecStop</span><span class="ot">=</span><span class="st">/usr/bin/kill -</span><span class="dv">15</span><span class="st"> $MAINPID</span>

<span class="kw">[Install]</span>
<span class="dt">WantedBy</span><span class="ot">=</span><span class="st">multi-user.target</span></code></pre></div>
<p>Now we can enable and start the fcgiwrap server for nginx</p>
<pre><code># systemctl enable nginx fcgiwrap
# systemctl start nginx fcgiwrap</code></pre>
<p>Hold with me, we are already done. The server is now able to run the gitweb cgi app on the root directory of the nginx server. The last thing, we need to do is giving gitweb the root directory, where it can find our repositories and set the URL according to the Git IP, which we used earlier. To configure these things we open up <em>/etc/gitweb.conf</em> and set the content like this:</p>
<pre><code>our $git_temp = &quot;/tmp&quot;;

# The directories where your projects are. Must not end with a slash.
our $projectroot = &quot;/home/git&quot;;

# Base URLs for links displayed in the web interface.
our @git_base_url_list = qw(git://192.168.178.48 http://git@192.168.178.48);

#Syntax Highlighting
$feature{&#39;highlight&#39;}{&#39;default&#39;} = [1];</code></pre>
<p>The tmp folder can stay as it is. The project root is the home directory of our Git user. You need to edit the Git URLs according to your Raspberry’s IP address, if it differs to mine. The last option enables highlighting of the shown source code on the Git web site, which looks like this</p>
<p><img src="/images/gitweb-diff.png" alt="Gitweb Diff" title="Gitweb Diff" /></p>
<p>A final restart is required for the changes to take effect</p>
<pre><code># systemctl restart nginx</code></pre>
<p>Now you can navigate the IP of your Raspberry Pi again, like when you were checking if the nginx server was running. You should now see your very own gitweb frontend.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Increase disk space of a vagrant machine</title>
    <link href="https://snow-dev.com/posts/increase-disk-space-of-a-vagrant-machine.html" />
    <id>https://snow-dev.com/posts/increase-disk-space-of-a-vagrant-machine.html</id>
    <published>2016-10-26T00:00:00Z</published>
    <updated>2016-10-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-10-26
    </section>
    <hr class="section-head">
    <section>
        <p>Lately I came across a rather big problem of vagrant: Increasing the disk space, because the normal 40GB were in use. There are options to increase RAM or CPU count easily. You can change it like this:</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provider <span class="st">&quot;virtualbox&quot;</span> <span class="kw">do</span> |vb|
    vb.memory = <span class="dv">4096</span>
    vb.cpus = <span class="dv">4</span>
<span class="kw">end</span></code></pre></div>
<p>So my thoughts were, that there must be a similar option to disk space as well, but there wasn’t. After some research I found out, there was no easy solution to that. There are already some solutions though, but nothing worked for me completely. I’m currently mainly using <a href="https://atlas.hashicorp.com/kaorimatz/boxes/ubuntu-16.04-amd64">kaorimatz ubuntu 16.04 iso.</a> One point which wasn’t working for me is, that other machines used lvm2 as a volume manager. Second problem was, that some people’s new increased hdd’s got attached automagically to the vagrant machine, even though it should give an UUID conflict. So I had to go for my own solution, which is a combination of various solutions out there. I hope this is of any use for someone else out there, who was as frustrated as I was.</p>
<h1 id="the-solution">The Solution</h1>
<p>First things first: This solution is for machines, which use VirtualBox as their virtualisation platform. If you use VirtualBox, we can go on. The first thing you have to do is turn your running vagrant machine off (<em>vagrant halt</em> or <em>vagrant suspend</em>). Next we need to find the actual VMDK file, which represents the HDD of the machine. If you have installed VirtualBox with the standard procedure, your machine should be here:</p>
<pre><code>/home/&lt;your username&gt;/VirtualBox\ VMs/&lt;name of the vm&gt;/&lt;name-of-the-disk&gt;.vmdk</code></pre>
<p>VMDK is a type, which can’t be resized. So, after we switched into the directory, the first thing we will do is converting it to VDI</p>
<pre><code>VBoxManage clonehd &lt;name-of-the-disk&gt;.vmdk tmp-disk.vdi --format vdi</code></pre>
<p>Now we are able to increase it</p>
<pre><code>VBoxManage modifyhd tmp-disk.vdi --resize &lt;size-in-MB&gt;</code></pre>
<p>As an example, if we want to have 60GB as the new size, the command would look like this</p>
<pre><code>VBoxManage modifyhd tmp-disk.vdi --resize 61440</code></pre>
<p>Now we convert it back to VMDK</p>
<pre><code>VBoxManage clonehd tmp-disk.vdi resized-disk.vmdk --format vmdk</code></pre>
<p>The next thing we need to do, is closing the SATA controller to the old disk</p>
<pre><code>VBoxManage storageattach &lt;name-of-the-vm&gt; --storagectl &quot;IDE Controller&quot; --port 0 --device 0 --medium none</code></pre>
<p>Here are two things, you need to take care of. First thing is <em><name-of-the-vm></em>. This is the same as the directory name, where the initial VMDK file is placed. The second thing is, that your storagectl could have another name. You can find it out by opening the _*.vbox_ file, which is in the same directory as the initial VMDK file. This should be a normal XML file. Now look out for this tag</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;StorageControllers&gt;</span>
  <span class="kw">&lt;StorageController</span><span class="ot"> name=</span><span class="st">&quot;IDE Controller&quot;</span><span class="ot"> type=</span><span class="st">&quot;PIIX4&quot;</span><span class="ot"> PortCount=</span><span class="st">&quot;2&quot;</span><span class="ot"> useHostIOCache=</span><span class="st">&quot;true&quot;</span><span class="ot"> Bootable=</span><span class="st">&quot;true&quot;</span><span class="kw">&gt;</span>
    <span class="kw">&lt;AttachedDevice</span><span class="ot"> type=</span><span class="st">&quot;HardDisk&quot;</span><span class="ot"> hotpluggable=</span><span class="st">&quot;false&quot;</span><span class="ot"> port=</span><span class="st">&quot;0&quot;</span><span class="ot"> device=</span><span class="st">&quot;0&quot;</span><span class="kw">&gt;</span>
      <span class="kw">&lt;Image</span><span class="ot"> uuid=</span><span class="st">&quot;{42b28bc6-a130-45be-9603-ee16779459d5}&quot;</span><span class="kw">/&gt;</span>
    <span class="kw">&lt;/AttachedDevice&gt;</span>
  <span class="kw">&lt;/StorageController&gt;</span>
<span class="kw">&lt;/StorageControllers&gt;</span></code></pre></div>
<p>As you can see, we are interested in the name of the <em>StorageController</em> tag. If there is something else than “IDE Controller”, you need to use that name for the <em>–storagectl</em> flag instead. Now we need to close the old medium</p>
<pre><code>VBoxManage closemedium disk &lt;name-of-the-disk&gt;.vmdk</code></pre>
<p>When it is closed, we can attach our new resized VMDK</p>
<pre><code>VBoxManage storageattach &lt;name-of-the-vm&gt; --storagectl &quot;IDE Controller&quot; --port 0 --device 0 --type hdd --medium resized-disk.vmdk</code></pre>
<p>Here you need to watch out for the same things, as in the last <em>storageattach</em> command. Now you should be able to restart your vagrant machine (<em>vagrant up</em>).  Afterwards SSH into it (<em>vagrant ssh</em>). Now you can check your disk space with</p>
<pre><code>df -h</code></pre>
<p>If there is your new size already, you are done. But if you are like me and still have the old size, we need to do some more steps. Namely we need to create a partition with the new space and resize our filesystem to that space. The following images are used from my example of increasing the disk from 40GB to 60GB, but there shouldn’t be a difference in doing the same for other sizes. First we need to search for our HDD</p>
<pre><code>sudo fdisk -l</code></pre>
<p>There are some USB drives and the last entry should look like this</p>
<p><img src="/images/fdisk.png" alt="Fdisk" title="Fdisk" /></p>
<p>Here we are interested in what comes after <em>Disk</em>. This should always be <em>/dev/sda</em>. If not, you continue using that name instead of <em>/dev/sda</em>. Next execute</p>
<pre><code>sudo fdisk /dev/sda</code></pre>
<p>You should have entered the fdisk prompt now, which looks like this</p>
<p><img src="/images/fdisk-prompt.png" alt="Fdisk-Prompt" title="Fdisk Prompt" /></p>
<p>Now type in <strong>p</strong> and Enter to execute. This should call the current partition table</p>
<p><img src="/images/fdisk-partition-table-1.png" alt="Fdisk Partition Table" title="Fdisk Partition Table" /></p>
<p>Here <em>/dev/sda1</em> should be the boot partition, <em>/dev/sda2</em> is the swap partition and <em>/dev/sda3</em> is the actual partition, which should be resized. If yours isn’t <em>/dev/sda3</em>, change the following commands to your partition name. First we delete the current <em>/dev/sda3</em> partition by typing in <strong>d</strong> and Enter. Now you should get to choose which one. We want to delete the 3. So we type in 3 + Enter.</p>
<p><img src="/images/fdisk-delete-partition.png" alt="Fdisk delete partition" title="Fdisk delete partition" /></p>
<p>Now we create a new one with <strong>n</strong> + Enter. Next we choose <strong>p</strong> for a primary partition. The new partition number will be 3 again and the next two questions for first and last sector will just be accepted with the default value by pressing Enter.</p>
<p><img src="/images/fdisk-new-partition.png" alt="Fdisk new Partition" title="Fdisk new Partition" /></p>
<p>As you can see we now have a new partition 3 with size 58.8 GB. To save the changes, we have made so far, type in <em>w</em> + Enter. This will result in an error like this</p>
<p><img src="/images/fdisk-write-changes.png" alt="Fdisk write changes" title="Fdisk write changes" /></p>
<p>As the messages tells us, the changes can’t be applied until a restart. That’s why we do exactly that. We leave the machine via exit and execute:</p>
<pre><code>vagrant reload</code></pre>
<p>After a few moments you should be able to re-SSH into your vagrant machine. The last thing we need to do is resize our file system to the new partition size.</p>
<pre><code>sudo resize2fs /dev/sda3</code></pre>
<p>If you do</p>
<pre><code>df -h</code></pre>
<p>again, you should now see the new size you’ve always wanted.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Creating your own PHP dev-env in Vagrant</title>
    <link href="https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant.html" />
    <id>https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-06-03
    </section>
    <hr class="section-head">
    <section>
        <h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html">Part 2</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html">Part 3</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html">Bonus 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html">Bonus 2</a></li>
<li><a href="https://github.com/snowiow/vagrant-template">Full Code Base on GitHub</a></li>
</ul>
<p>In this series of posts we will be creating a development environment(dev-env) for PHP with the help of <a href="https://www.vagrantup.com">vagrant</a>. Vagrant is a thin wrapper around different <a href="https://en.wikipedia.org/wiki/Virtualization">virtualization software</a> projects like <a href="https://www.virtualbox.org">virtual box</a>, which we will be using in this tutorial. The so called wrapper of vagrant is a configuration file, written in the <a href="http://www.ruby-lang.org/en/">ruby programming language</a>. But don’t worry, you don’t need to be an expert ruby programmer to setup a dev-env in vagrant. Everything we use it for, are some variable assignments. In this configuration file we can tell the virtualization software, which operating system and software to install and how to configure everything. Our ultimate goal here is, if the environment is started, everything is setup already. Finally we want to get a fully configured LAMP stack with a running apache webserver, a mysql database and PHP. As always there are many different ways to glory. For example does vagrant offer different ready to use recipes via <a href="https://github.com/ShawnMcCool/vagrant-chef">chef</a>. There is also support for <a href="https://www.vagrantup.com/docs/provisioning/puppet_apply.html">Puppet</a>, a unified configuration language for different systems. We won’t use any of these plugins in this series. Everything we will work with, are some bash scripts and the vagrant file. I have chosen this path, because I want to keep the full control over everything. On the other hand it’s also more work, but I think it’s worth it. Before we go into the details, lets talk about the advantages of a vagrant based development environments.</p>
<h1 id="benefits">Benefits</h1>
<p>The most obvious benefit is that we will have one file, which handles the complete configuration. As soon as it is written, we can use it over and over again. We can upload the file to git and download it on other machines to get the same dev-env everywhere we work. We can share it with other programmers in a team, so everyone is working in the same environment. Sentences like “…but it works on my machine” lie in the past now. Best case scenario would be to replicate the environment of the production system. In this case, you are able to catch any environmental issues locally, before they go live. The second benefit is a PHP specific one. Languages like python have built-in features to run different versions of the language for different projects and also manage their respective packages(<a href="https://pypi.python.org/pypi/virtualenv">virtalenv</a>). In PHP it’s pretty difficult to comfortably run different versions on one system. There are however some approaches like <a href="https://github.com/phpbrew/phpbrew">phpbrew</a> to handle this problem. Vagrant is another option. Here you just start the vagrant machine with the respective version of PHP installed. The final benefit is that you interact with everything inside of vagrant from your physical machine. You can use your preferred IDE to code your app. You can reach the webserver via your normal webbrowser. You can view the database over a ssh connection and so on. In this domain your physical machine is called the host machine and the operating system inside vagrant is the guest. So lets list up our final goals, we want to archieve at the end of this tutorial.</p>
<h1 id="goals">Goals</h1>
<ul>
<li>Having a one line command to fire up the whole dev-env(vagrant up)</li>
<li>Access the served sites via your preferred web browser on your host system</li>
<li>Setup Virtual hosts to access the site via a pretty looking URL</li>
<li>Access the database over a ssh connection with workbench or PHPMyAdmin on your hosts web browser</li>
<li>Having a shared fdirectory between host and guest system, to be able to code on your host system and let the changes take effect immediately</li>
</ul>
<h1 id="installation">Installation</h1>
<p>You need to install two things to get started. The first thing is vagrant of course. You can download it from their <a href="https://www.vagrantup.com/downloads.html">official homepage</a>. I personally installed vagrant with my package manager on arch linux. This isn’t recommended by hashicorp, but I never had problems so far. The second thing you will need is VirtualBox, which will be our virtualization software of choice. Again you can either download it from <a href="https://www.virtualbox.org/wiki/Downloads">their official website</a> or install it via your package manager. Those are all the things you need to get yourself into the getting started section.</p>
<h1 id="getting-started">Getting started</h1>
<p>We want to create a vagrant subdirectory in a project directory. Our goal in this tutorial is to have vagrant as a subdirectory of the project folder, where our PHP web app lives. So we can upload anything to git together. Our “project” will just be a phpinfo file, but it can be substituted by any project, you are currently working on.</p>
<pre class="shell"><code>cd path-to-project &amp;&amp; mkdir vagrant</code></pre>
<p>Afterwards we switch into that directory and initiate a new vagrant project.</p>
<pre><code>cd vagrant &amp;&amp; vagrant init</code></pre>
<p>This will create a file called <em>Vagrantfile</em> in your newly created directory. This is the configuration we talked about in the beginning of this post. If you open it, you see some ruby code, which consists of some assignments and many comments. We won’t cover anything in detail here, because we want to focus on our mission and get our goals done. If you want to know more about the other stuff in the <em>Vagrantfile</em>, you can head to the <a href="https://www.vagrantup.com/docs/getting-started/">official documentation</a> of vagrant, which is very well written. So let’s get into the first two lines of code.</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby"><span class="dt">Vagrant</span>.configure(<span class="dv">2</span>) <span class="kw">do</span> |config|
  config.vm.box = <span class="st">&quot;base&quot;</span></code></pre></div>
<p>The first line stays as it is. It tells vagrant on which version this config is based. The second line says what operating system image should be used. These are called boxes in the vagrant domain. We will use a basic ubuntu 14.04 installation as our basis. That’s why we change the second line to this:</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.box = <span class="st">&quot;ubuntu/trusty64&quot;</span></code></pre></div>
<p>For a full list of available boxes have a look into <a href="https://atlas.hashicorp.com/boxes/search">this</a>. Here you can find all different kinds of boxes. Starting off with very basic ones, up to fully configured environments. The next line we are interested in is the following:</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby"><span class="co"># config.vm.synced_folder &quot;../data&quot;, &quot;/vagrant_data&quot;</span></code></pre></div>
<p>This line tells vagrant which directory of the host system should be mapped to a directory inside the guest system. These are called synced folders, because any operation happening in this directory is instantly visible on both systems. As you may noticed, this will be the location, where our code base will be placed. For the moment, we will edit this line of code to the following:</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.synced_folder <span class="st">&quot;../&quot;</span>, <span class="st">&quot;/vagrant/projects/&quot;</span></code></pre></div>
<p>The first argument is the directory on the host system. The second argument is the path inside the guest system. It will be created automatically on startup of the vagrant machine. So we don’t need to do anything there for the moment. The last thing we uncomment for the moment is this one</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby"><span class="co"># config.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.10&quot;</span></code></pre></div>
<p>We don’t change anything except for deleting the hash tag at the beginning. As soon as this line is active, vagrant starts up a private network connection, which is only accessible by the host system. This will also be the IP address where our web application will be available later on. You can change the IP to anything you want, but remember to change the later occurrences, where we work with this particular IP as well. This is the end of our intro. In the following chapter we will write our first shell scripts to setup the apache webserver.<br />
<a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html">Go to Part 2</a></p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Creating your own PHP dev-env in Vagrant: Part 3</title>
    <link href="https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html" />
    <id>https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-06-03
    </section>
    <hr class="section-head">
    <section>
        <h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant.html">Part 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html">Part 2</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html">Bonus 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html">Bonus 2</a></li>
<li><a href="https://github.com/snowiow/vagrant-template">Full Code Base on GitHub</a></li>
</ul>
<p>In the previous post we’ve set up the apache web server successfully. Now it’s time to add MySQL and PHP to finish the LAMP stack. Let’s start with MySQL first and add a <em>mysql.sh</em> file to the <strong>sh</strong> directory. We write the following lines into that file.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;mysql-server mysql-server/root_password password my_pw&quot;</span>
<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;mysql-server mysql-server/root_password_again password my_pw&quot;</span>
<span class="ex">apt-get</span> install -y mysql-server libapache2-mod-auth-mysql</code></pre></div>
<p>The first two lines set values for the upcoming installation dialog of MySQL. The installation dialog will ask us for a password and to repeat it. Because we want to setup MySQL automatically without any interaction, we preset those fields with our password of choice. In this case <strong>my_pw</strong>. Afterwards we install MySQL and an extra package for apache. Afterwards we copy over the config file of MySQL onto the guest system.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /vagrant/tmp/my.cnf<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">mv</span> /vagrant/tmp/my.cnf /etc/mysql/my.cnf
<span class="kw">else</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Error: my.cnf not found&quot;</span>
<span class="kw">fi</span></code></pre></div>
<p>We do it exactly the same way, as we did with the <em>apache.conf</em>. First we place the <em>my.cnf</em> in our <em>conf</em> directory. Afterwards we add a file provisioner to our <em>Vagrantfile</em>.</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provision <span class="st">&quot;file&quot;</span>, <span class="st">source: &quot;conf/my.cnf&quot;</span>, <span class="st">destination: &quot;/vagrant/tmp/my.cnf&quot;</span></code></pre></div>
<p>This time it’s important to replace a custom config file with the original, because in our modified version we switch the following line from:</p>
<pre><code>bind-address = 127.0.0.1</code></pre>
<p>to</p>
<pre><code>bind-address = 0.0.0.0</code></pre>
<p>Before it was only possible to access the database on the guest machine itself. We changed this, so we can connect from the host machine as well. Finally we need to restart the MySQL demon.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">service</span> mysql restart</code></pre></div>
<p>With which we end up in our final <em>mysql.sh</em> file, which looks like this:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env bash</span>

<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;mysql-server mysql-server/root_password password my_pw&quot;</span>
<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;mysql-server mysql-server/root_password_again password my_pw&quot;</span>
<span class="ex">apt-get</span> install -y mysql-server libapache2-mod-auth-mysql php5-mysql

<span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /vagrant/tmp/my.cnf<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">mv</span> /vagrant/tmp/my.cnf /etc/mysql/my.cnf
<span class="kw">else</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Error: my.cnf not found&quot;</span>
<span class="kw">fi</span>

<span class="ex">service</span> mysql restart</code></pre></div>
<p>Final thing we need to do is adding the shell script as a shell provisioner to our <em>Vagrantfile</em>.</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/mysql.sh&quot;</span></code></pre></div>
<p>Now let’s install PHP as well. This is pretty straight forward. Our <em>php.sh</em> looks like this:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env bash</span>
<span class="ex">apt-get</span> install -y php5 libapache2-mod-php5 php5-mcrypt php5-curl php5-mysql</code></pre></div>
<p>Afterwards we also add it as a provisioner</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/php.sh&quot;</span></code></pre></div>
<p>Which results in the following <em>Vagrantfile</em></p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby"><span class="dt">Vagrant</span>.configure(<span class="dv">2</span>) <span class="kw">do</span> |config|
  config.vm.box = <span class="st">&quot;ubuntu/trusty64&quot;</span>

  config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/update.sh&quot;</span>
  config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/apache.sh&quot;</span>
  config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/mysql.sh&quot;</span>
  config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/php.sh&quot;</span>

  config.vm.provision <span class="st">&quot;file&quot;</span>, <span class="st">source: &quot;conf/apache2.conf&quot;</span>, <span class="st">destination: &quot;/vagrant/tmp/apache2.conf&quot;</span>
  config.vm.provision <span class="st">&quot;file&quot;</span>, <span class="st">source: &quot;conf/my.cnf&quot;</span>, <span class="st">destination: &quot;/vagrant/tmp/my.cnf&quot;</span>

  config.vm.network <span class="st">&quot;private_network&quot;</span>, <span class="st">ip: &quot;192.168.33.10&quot;</span>

  config.vm.synced_folder <span class="st">&quot;../&quot;</span>, <span class="st">&quot;/vagrant/projects/&quot;</span>
<span class="kw">end</span></code></pre></div>
<p>This is it. Our LAMP stack is complete. Now we want to check out our environment. Switch into the directory of the <em>Vagrantfile</em> and execute the following command</p>
<pre><code>vagrant up</code></pre>
<p>A lot of stuff is happening now and for the first time it will take some time to fire up the vagrant machine. If vagrant booted up successfully, we add an <em>index.php</em> in the directory above our <em>Vagrantfile</em>. This is our project directory. I won’t show anything big here, just a proof of concept</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php"><span class="kw">&lt;?php</span>

<span class="fu">phpinfo</span><span class="ot">();</span></code></pre></div>
<p>If you browse to <strong>192.168.33.10</strong> on your host system, you should see an info page about the running PHP version, similar to this</p>
<p><img src="/images/phpinfo.png" alt="phpinfo" title="phpinfo" /></p>
<p>Congratulations! You’ve done it! To suspend your vagrant machine just type the following in the same spot, where you did the <em>vagrant up</em></p>
<pre><code>vagrant suspend</code></pre>
<p>This saves the state of your machine and will be the way to shut it down in daily business. If you want to completely reset your machine and install everything again, you execute</p>
<pre><code>vagrant destroy</code></pre>
<p>To start your vagrant machine, just do <em>vagrant up</em> again. You could start from here and put your own PHP project in the parent directory of the <em>Vagrantfile</em> and start programming. But if you want to know some nifty stuff, like how to access your website via an address like <em>mysite.dev</em> instead of 192.168.33.10 or how you can access your database with the <strong>mysql-workbench</strong> software on your host machine, you should definitely check out the next posts in this series. <a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html">Go to Bonus 1</a></p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Creating your own PHP dev-env in Vagrant: Part 2</title>
    <link href="https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html" />
    <id>https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-06-03
    </section>
    <hr class="section-head">
    <section>
        <h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant.html">Part 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html">Part 3</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html">Bonus 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html">Bonus 2</a></li>
<li><a href="https://github.com/snowiow/vagrant-template">Full Code Base on GitHub</a></li>
</ul>
<p>In the last post we installed vagrant and enabled the vagrant settings we need in the Vagrantfile. We have set a base image of ubuntu 14.04, made a synced folder and enabled a private network connection between host and guest system. Now it’s time to write our first shell scripts, which will configure our guest system to serve as a web server. Vagrant comes with a neat feature called provisioning. This can be shell scripts, which will be executed or files, which will be uploaded onto the guest system. Of course there are more provisioners to explore. For a full reference head over <a href="https://www.vagrantup.com/docs/provisioning/">here</a>. In this tutorial we will focus on these two provisioners. Before we setup our apache webserver, let’s start with a simple script, which should run before. This script will update the ubuntu system and should be a great intro into provisioning. First we create a new directory inside of our vagrant directory, called <strong>sh</strong>. This directory will contain all of our shell scripts, which we will write during this tutorial. Everything could be in a single shell script, but I like to split the shell scripts into specific categories. The first will be called <em>update.sh</em> and contains the the following content:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env bash</span>

<span class="ex">apt-get</span> update</code></pre></div>
<p>The first line will be in every script we write. It’s a dynamic binding to tell the operating system where to find the program, which should execute this script. Afterwards we update the system by executing <em>apt-get update</em>. As you can see, we don’t need to issue <em>sudo</em> rights. Everything inside these shell scripts will be run as a super user automagically. Now we need to get vagrant to provision this file. That’s why we add the following line after the definition of our base system.</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.box = <span class="st">&quot;ubuntu/trusty64&quot;</span>
config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/update.sh&quot;</span></code></pre></div>
<p>This statement is pretty straight forward. We tell vagrant that we want to provision something, which is of the type <em>shell</em> and the path to the shell script is <em>sh/update.sh</em>. If we would start our system now, it would do a system update at the beginning. Now that we are working on the latest state of the system, we can start adding new software. It’s time to create the apache webserver. We add a new filed called <em>apache.sh</em> to the sh directory, which we created earlier. We start off in the same way, by downloading the software via apt-get:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">apt-get</span> install -y apache2</code></pre></div>
<p>Followed by this:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">if</span> !<span class="bu"> [</span> <span class="ot">-L</span> /var/www/html<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">rm</span> -rf /var/www/html
    <span class="fu">ln</span> -fs /vagrant/projects /var/www/html
<span class="kw">fi</span></code></pre></div>
<p>Here we delete any symlinks on the <em>/var/www/html</em> location, if they exist and create a new one afterwards. The symlink will be between our projects directory and the apache web server. So everything which changes in one place, will automatically change in the other location as well. It’s like the synced folders, but it’s an inter system feature of linux. The next part is optional. I copied the whole <em>apache.conf</em> out of it’s base installation and keep it on my host system to change some things. On system startup I copy it back onto the guest and replace the base config with it.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /vagrant/tmp/apache2.conf<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">mv</span> /vagrant/tmp/apache2.conf /etc/apache2/apache2.conf
<span class="kw">else</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Error: apache2.conf not found&quot;</span>
<span class="kw">fi</span></code></pre></div>
<p>This is a check, if a file is in the <em>vagrant/tmp</em> directory, called <em>apache2.conf</em>. If there is one, it will be moved over to the position of the original file. Otherwise an error is printed to the error channel of the console. But how do we get the file to the <em>tmp</em> directory? Remember that shell provision isn’t the only thing? Because now file provisioning comes into play.</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provision <span class="st">&quot;file&quot;</span>, <span class="st">source: &quot;conf/apache2.conf&quot;</span>, <span class="st">destination: &quot;/vagrant/tmp/apache2.conf&quot;</span></code></pre></div>
<p>We add this line under the shell provision. This copies the file from the <em>conf</em> directory to the <em>tmp</em> directory of the guest system. Why we need to do this extras step, you may ask? Why not copy it directly to the original location? Well, it’s pretty simple: In the provision context you don’t have any root rights. But later in the shell script you do. That’s why we provide a place for our files, where the shell scripts have access to later. The next thing I do, is changing the rights on the webspace and the log directory, to be able to create and read files without any problems.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">chmod</span> -R 755 /var/www
<span class="fu">chmod</span> -R 755 /var/log</code></pre></div>
<p>The last thing I do is activating mod rewrite, which allows web applications to rewrite the routing of requests. Many frameworks rely heavily on this feature.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">a2enmod</span> rewrite</code></pre></div>
<p>And this is our full <em>apache2.sh</em> script:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#!/usr/bin/env bash</span>

<span class="ex">apt-get</span> install -y apache2

<span class="co">#Symlink the apache webspace to the shared folder of the host and guest syste,</span>
<span class="kw">if</span> !<span class="bu"> [</span> <span class="ot">-L</span> /var/www/html<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">rm</span> -rf /var/www/html
    <span class="fu">ln</span> -fs /vagrant/projects /var/www/html
<span class="kw">fi</span>

<span class="co">#Copy the apache2.conf to the right location</span>
<span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /vagrant/tmp/apache2.conf<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">mv</span> /vagrant/tmp/apache2.conf /etc/apache2/apache2.conf
<span class="kw">else</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Error: apache2.conf not found&quot;</span>
<span class="kw">fi</span>

<span class="co">#grant permission to webserver</span>
<span class="fu">chmod</span> -R 777 /var/www
<span class="fu">chmod</span> -R 777 /var/log

<span class="co">#enable mod_rewrite</span>
<span class="ex">a2enmod</span> rewrite</code></pre></div>
<p>In the next part we will reach forward to install php and mysql. You already learned the main functionalities, which we need to get our dev-env running. From now on it gets far more repetitive, but some small challenges are still waiting on our way. <a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html">Go to Part 3</a></p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Creating your own PHP dev-env in Vagrant: Bonus 2</title>
    <link href="https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html" />
    <id>https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-06-03
    </section>
    <hr class="section-head">
    <section>
        <h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant.html">Part 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html">Part 2</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html">Part 3</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html">Bonus 1</a></li>
<li><a href="https://github.com/snowiow/vagrant-template">Full Code Base on GitHub</a></li>
</ul>
<p>Slowly but surely we get to the end of this series. In this last post, I will write about database access from the host system, while your database is running on the guest machine. Therefore I will present two strategies to do so. Sure you also can</p>
<pre><code>vagrant ssh</code></pre>
<p>via the terminal and access the database on the CLI. But viewing and fast editing of some tables is much more comfortable from a GUI. In this post I will go over two MySQL applications: MySQL Workbench and PHPMyAdmin. While the Workbench will be installed on your host system and access the database via ssh, PHPMyAdmin will be installed on the guest system, on the existing apache web server. Here we are able to access it over the hosts browser like our web app.</p>
<h1 id="mysql-workbench">MySQL Workbench</h1>
<p>The MySQL Workbench can be installed via your package manager or from their <a href="https://dev.mysql.com/downloads/workbench/">website</a>. After the installation we start up the vagrant machine and open the workbench. You should see this area.</p>
<p><img src="/images/workbench-one.png" alt="Workbench 1" title="Workbench 1" /></p>
<p>Click on the “+” next to the MySQL Connections. Now a new dialog should open up.</p>
<p><img src="/images/workbench2.png" alt="Workbench 2" title="Workbench 2" /></p>
<p>Choose “Standard TCP/IP over SSH”. Afterwards fill out SSH Hostname and SSH username, like I did. At the top you can choose whatever name you like for the Connection Name. Then press Ok. Afterwards you should see your newly created Connection.</p>
<p><img src="/images/workbench3.png" alt="Workbench 3" title="Workbench 3" /></p>
<p>Double-Click it and you will be asked for the SSH password. Since we didn’t changed it yet, it’s still <em>vagrant</em>. Then you will be asked for the database password. If you followed this tutorial closely, this will be <strong>my_pw</strong>. Afterwards you should be logged into your database successfully and you can start interacting with it.</p>
<h1 id="phpmyadmin">PHPMyAdmin</h1>
<p>Here we process similar, like we did in the earlier posts. First we create a new shell script inside of our <strong>sh</strong> directory. We start off with the following content</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2&quot;</span>
<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;phpmyadmin phpmyadmin/dbconfig-install boolean true&quot;</span>
<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;phpmyadmin phpmyadmin/mysql/admin-pass password my_pw&quot;</span> 
<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;phpmyadmin phpmyadmin/mysql/app-pass password my_pw&quot;</span>
<span class="ex">debconf-set-selections</span> <span class="op">&lt;&lt;&lt;</span> <span class="st">&quot;phpmyadmin phpmyadmin/app-password-confirm password my_pw&quot;</span></code></pre></div>
<p>This should look similar to you. We already did it, while installing MySQL. Because PHPMyAdmin is working with an interactive prompt as well, we pass the different parameters in before. Out of simplicity we go with <em>my_pw</em> as our password again. Now we can install it</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">apt-get</span> install -y phpmyadmin
<span class="ex">php5enmod</span> mcrypt</code></pre></div>
<p>On PHP5 we need to enable the mcrypt library, otherwise we get an annoying red box inside of our PHPMyAdmin Frontend. The last part of our config looks like this.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /vagrant/tmp/phpmyadmin.conf<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">mv</span> /vagrant/tmp/phpmyadmin.conf /etc/apache2/sites-available/phpmyadmin.conf
    <span class="ex">a2ensite</span> phpmyadmin.conf
<span class="kw">else</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Error: phpmyadmin.conf not found&quot;</span>
<span class="kw">fi</span>

<span class="ex">service</span> apache2 restart</code></pre></div>
<p>We put a virtual host configuration for the PHPMyAdmin page into the right place, like we did with our web app in the last post. Finally we restart the apache server. Our <em>phpmyadmin.conf</em> looks like this</p>
<div class="sourceCode"><pre class="sourceCode apache"><code class="sourceCode apache"><span class="fu">&lt;VirtualHost</span><span class="at"> *:80</span><span class="fu">&gt;</span>
    ServerAdmin<span class="st"> webmaster@dummy-host.com</span>
    DocumentRoot<span class="st"> &quot;/usr/share/phpmyadmin&quot;</span>
    ServerName<span class="st"> phpmyadmin.dev</span>
    ServerAlias<span class="st"> www.phpmyadmin.dev</span>
    ErrorLog<span class="st"> &quot;/var/log/apache2/phpmyadmin.dev-error_log&quot;</span>
    CustomLog<span class="st"> &quot;/var/log/apache2/phpmyadmin.dev-access_log&quot; common</span>
    <span class="fu">&lt;Directory</span><span class="at"> &quot;/usr/share/phpmyadmin&quot;</span><span class="fu">&gt;</span>
       <span class="ex">Options</span><span class="ch"> </span><span class="kw">Indexes</span><span class="ch"> </span><span class="kw">FollowSymLinks</span><span class="ch"> </span><span class="kw">Includes</span><span class="ch"> </span><span class="kw">MultiViews</span>
       <span class="ex">Order</span><span class="ch"> </span><span class="kw">allow,deny</span>
       Allow<span class="st"> from all</span>
       <span class="ex">AllowOverride</span><span class="ch"> </span><span class="kw">All</span>
   <span class="fu">&lt;/Directory&gt;</span>
<span class="fu">&lt;/VirtualHost&gt;</span></code></pre></div>
<p>This is almost the same, like we did in the last post, except for the new paths. Additionally we set some more directory options for PHPMyAdmin to make it’s routing possible. Next thing to do is add these scripts as partitioners to our Vagrantfile.</p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provision <span class="st">&quot;shell&quot;</span>, <span class="st">path: &quot;sh/phpmyadmin.sh&quot;</span>
config.vm.provision <span class="st">&quot;file&quot;</span>, <span class="st">source: &quot;conf/phpmyadmin.conf&quot;</span>, <span class="st">destination: &quot;/vagrant/tmp/phpmyadmin.conf&quot;</span></code></pre></div>
<p>Now we are only missing an entry in our hosts file, to make the new domain address known to our host machine. So we go to our <em>hosts</em> file again and add the following line</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="dt">192.168.33.10 	phpmyadmin.dev</span></code></pre></div>
<p>That’s it! Recreate or re-provision your vagrant machine and go to <em>phpmyadmin.dev</em> on your hosts web browser. You should see this page</p>
<p><img src="/images/phpmyadmin.png" alt="PHPMyAdmin" title="PHPMyAdmin" /></p>
<p>Type in the credentials you have typed in earlier and you should be able to be in the web frontend of your database.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>Creating your own PHP dev-env in Vagrant: Bonus 1</title>
    <link href="https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html" />
    <id>https://snow-dev.com/posts/creating-your-own-php-dev-env-in-vagrant-bonus-1.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-06-03
    </section>
    <hr class="section-head">
    <section>
        <h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant.html">Part 1</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-2.html">Part 2</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-part-3.html">Part 3</a></li>
<li><a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html">Bonus 2</a></li>
<li><a href="https://github.com/snowiow/vagrant-template">Full Code Base on GitHub</a></li>
</ul>
<p>In the previous posts we’ve successfully set up a development environment for PHP. In the following posts I will present some bonus things, which you can do, to optimize your work with vagrant. In this post I will show you how to set a virtual host in apache inside your guest system. Because IP addresses can be forgotten quite easily, it’s much more handy to have a short named address under which you can access your web app. In this project we will create a virtual host for our main project directory called <em>mysite.dev</em>. So let’s get started! First we create a config file inside our <em>conf</em> directory with the following content:</p>
<div class="sourceCode"><pre class="sourceCode apache"><code class="sourceCode apache"><span class="fu">&lt;VirtualHost</span><span class="at"> *:80</span><span class="fu">&gt;</span>
    DocumentRoot<span class="st"> &quot;/var/www/html&quot;</span>
    ServerName<span class="st"> mysite.dev</span>
    ServerAlias<span class="st"> www.mysite.dev</span>
    ErrorLog<span class="st"> &quot;/var/log/apache2/mysite.dev-error_log&quot;</span>
    CustomLog<span class="st"> &quot;/var/log/apache2/mysite.dev-access_log&quot; common</span>
    <span class="fu">&lt;Directory</span><span class="at"> &quot;/var/www/html&quot;</span><span class="fu">&gt;</span>
       <span class="ex">Order</span><span class="ch"> </span><span class="kw">allow,deny</span>
       Allow<span class="st"> from all</span>
       <span class="ex">AllowOverride</span><span class="ch"> </span><span class="kw">All</span>
   <span class="fu">&lt;/Directory&gt;</span>
<span class="fu">&lt;/VirtualHost&gt;</span></code></pre></div>
<p>This is the virtual host definition. The first line says that it’s listening on port 80, which is the default port. The <em>DocumentRoot</em> is the path to our webspace, which was symlinked to the vagrant synced directory in an earlier post. <em>ServerName</em> is the address, how you can access the page and the <em>ServerAlias</em> is the alternative if the <em>ServerName</em> isn’t accessible. The following two lines are the paths to the access and error log of our virtual host. If anything bad happens, those two files are the place to start troubleshooting. The following lines are some directory options about what the web app is allowed to do and what not. Next we need a new shell script, which we call <em>mysite.sh</em>. Everything required to setup your project(composer update, migrations etc.) will be defined in this script. In this tutorial we won’t do all this, but only activating our virtual host address.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /vagrant/tmp/mysite.conf<span class="bu"> ]</span>; <span class="kw">then</span>
    <span class="fu">chown</span> <span class="va">$USER</span>:<span class="va">$USER</span> /var/www/html
    <span class="fu">mv</span> /vagrant/tmp/mysite.conf /etc/apache2/sites-available/mysite.conf
    <span class="ex">a2ensite</span> mysite.conf
<span class="kw">else</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Error: mysite.conf not found&quot;</span>
<span class="kw">fi</span></code></pre></div>
<h1 id="make-changes-effective">Make changes effective</h1>
<pre><code>service apache2 restart</code></pre>
<p>Most of this should be familiar to you from the previous chapters. First we check if the file exists in our temp directory. If it does, we create the directory for our project and set the owner of this directory. Afterwards we move the file to the <em>sites-available</em> directory of apache and enable it. To make sure all settings are active, we restart the apache demon. As you already know, we need to get the <em>mysite.conf</em> into the <em>tmp</em> directory. That’s why we add another file provisioner to our <em>Vagrantfile.</em></p>
<div class="sourceCode"><pre class="sourceCode ruby"><code class="sourceCode ruby">config.vm.provision <span class="st">&quot;file&quot;</span>, <span class="st">source: &quot;conf/mysite.conf&quot;</span>, <span class="st">destination: &quot;/vagrant/tmp/mysite.conf&quot;</span></code></pre></div>
<p>To activate the new provision you either need to execute</p>
<pre><code>vagrant reload --provision</code></pre>
<p>Or <em>vagrant destroy</em> and <em>vagrant up</em> again. The last step is to make the virtual host known to your host system. For this, you need to add a line into your hosts file. On unix like systems you can find the file in the <em>/etc/</em> directory. The file should begin with the following</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="co">#</span>
<span class="co"># /etc/hosts: static lookup table for host names</span>
<span class="co">#</span>

<span class="co">#&lt;ip-address&gt;	&lt;hostname.domain.org&gt;	&lt;hostname&gt;</span></code></pre></div>
<p>After this intro we add the following line</p>
<div class="sourceCode"><pre class="sourceCode ini"><code class="sourceCode ini"><span class="dt">192.168.33.10 mysite.dev</span></code></pre></div>
<p>Which maps the IP address of our private network hosted by vagrant to a domain name. Ok let’s check it out. Type in <em>mysite.dev</em> into the address bar of your browser. You should now see the php info page from the last tutorial. In the next post I want to cover the database access. I will show two ways to you, how you can interact with your database from your host system. The first way will be with MySQL Workbench via an SSH connection. The second is by installing PHPMyAdmin on the guest system and access it via the hosts web browser. <a href="/posts/creating-your-own-php-dev-env-in-vagrant-bonus-2.html">Go to Bonus 2</a></p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>The power of Vim Plugins: Vim-Plug</title>
    <link href="https://snow-dev.com/posts/the-power-of-vim-plugins-vim-plug.html" />
    <id>https://snow-dev.com/posts/the-power-of-vim-plugins-vim-plug.html</id>
    <published>2016-04-03T00:00:00Z</published>
    <updated>2016-04-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-04-03
    </section>
    <hr class="section-head">
    <section>
        <p>A few weeks after my <a href="http://snow-dev.com/the-power-of-vim-plugins-vundle/">Vundle</a> post, I stumbled upon a plugin manager called <a href="https://github.com/junegunn/vim-plug">vim-plug</a>. It sounded very promising and I checked it out. Until today I didn’t go back to Vundle. This is almost half a year ago and I think it’s time to write something up about this amazing plugin manager. When you enter the GitHub page you see a bunch of pros, why this plugin manager is so awesome. Two points stood out for me though. Point one is the utilization of asynchronous downloads and installation, which makes the whole process of installing and updating a whole lot faster. If you installed your vim with the +python/+python3 or +ruby flag, you are able to use this feature. The alternative is to install <a href="https://neovim.io/">neovim</a>, which comes with asynchronous batteries included. The second point is “On-demand loading for faster startup time”. This line says, you are able to give every plugin some options, when they should be loaded up. For example, if you program in more than one language, say PHP and C++. Now you got some language specific plugins for example <a href="https://github.com/rhysd/vim-clang-format">clang-format</a>, which formats your C++ Code. Having the plugin loaded up, only makes sense if you are in a C++ file, right? With the help of vim-plug you are now able to delay the startup of clang-format until you open a C++ file for the first time. This isn’t the only lazy load option. We will cover this feature in depth in a later section. As I looked through my plugin list I got about one half of my plugins which didn’t need to be loaded on startup. After setting these options, my startup time increased quite a bit. If you are convinced either by me or because of the rest of pro list, let’s get started with the installation.</p>
<h1 id="installation">Installation</h1>
<p>The installation is pretty straight forward. The GitHub page gives you 3 different commands. If you use normal vim on Unix, you need to execute the following line:</p>
<pre><code>curl -fLo ~/.vim/autoload/plug.vim --create-dirs</code></pre>
<p>If you use neovim and you don’t have your default vim location symlinked, you need to change the destination path:</p>
<pre><code>curl -fLo ~/.config/nvim/autoload/plug.vim --create-dirs</code></pre>
<p>Now that you have vim-plug installed you need a section at the beginning of your <em>.vimrc</em>, which looks like this:</p>
<pre class="vim"><code>call plug#begin(&#39;~/.vim/plugged&#39;)

call plug#end()</code></pre>
<p>With this template you are ready to go for the next steps.</p>
<h1 id="configuration">Configuration</h1>
<p>Adding plugins from GitHub is as easy as the following line. You need to place these between the 2 lines, which we added at the end of the last section.</p>
<pre><code>Plug &#39;scrooloose/nerdtree&#39;</code></pre>
<p>If you are using another source than GitHub, you can put the full git path between the quotes. Pay attention to the ending of the URL:</p>
<pre><code>Plug &#39;https://github.com/scrooloose/nerdtree.git&#39;</code></pre>
<p>Thats it! Now you can install that Plugin via the <em>:PlugInstall</em> command. Another tiny benefit is, that you save 2 characters in each command. You just type <em>:PlugInstall</em> for vim-plug instead of <em>:PluginInstall</em> in Vundle. The same goes for updating existing packages, which is <em>:PlugUpdate</em> instead of <em>:PluginUpdate</em>. This is only a small thing, but I really like this, since I’ve switched. The second important feature I use very often is to remove packages. For this you just remove the line</p>
<pre><code>Plug &#39;scrooloose/nerdtree&#39;</code></pre>
<p>Afterwards you call <em>:PlugClean</em>. Now you get a prompt with the plugins, which should get deleted. You can accept with [y]es or [n]o. To skip this prompt, you can also type in the command <em>:PlugClean!</em>. Now we are coming to one of the main advantages: The on-demand loading. As described in the beginning, this delays the loading of the plugin until something specific happens. This is great because vim doesn’t load up all plugins on startup, which improves your startup time quite a bit. Let’s get to our first example, where I want to show you the <strong>on</strong> keyword. The <strong>on</strong> keyword loads a plugin, when a specific command was executed. Those options will be written as JSON after the plugin path. For example, we want to load NERDTree when <em>:NERDTreeToggle</em> was executed for the first time.</p>
<pre><code>Plug &#39;scrooloose/nerdtree&#39;, {&#39;on&#39;: &#39;NERDTreeToggle&#39;}</code></pre>
<p>As you can see, we split up the line by a comma. Afterwards we write down a JSON string, where <strong>on</strong> is the key and the command(without the colon) is the value. That’s everything! Now NERDTree load will be delayed until this command is executed. The second keyword I use pretty often is <strong>for</strong>. This keyword loads plugins for specific filetypes. Let’s take the C++ plugin clang-format from the intro, which formats C++ code according to some sort of standard. This plugin is only useful to us, if we work on C++ files. That’s why we want to delay the loading of this plugin until we work on a C++ file for the first time</p>
<pre><code>Plug &#39;rhysd/vim-clang-format&#39;, {&#39;for&#39;: &#39;cpp&#39;}</code></pre>
<p>And here we go. Clang-fromat will be lazy loaded when we open a C++ file for the first time. The last keyword which is pretty useful is <strong>do</strong>. It’s used for plugins, which need another third party component to be compiled. One example is <a href="https://github.com/Valloric/YouCompleteMe">YouCompleteMe</a>, an autocompletion engine for vim. If you want to have C++ semantic completion support, you need to compile another component, which is used by this plugin. The compilation is triggered via a python script, which downloads clang and compiles the component afterwards. Normally you do this manually after each update, but you are also able to tell vim-plug to execute it after the plugin update automatically. To make it happen add the following line to your <em>.vimrc</em>.</p>
<pre><code>Plug &#39;Valloric/YouCompleteMe&#39;, { &#39;do&#39;: &#39;./install.py&#39; }</code></pre>
<p>Now everytime YouCompleteMe is updated, the third party component will be recompiled automatically and you don’t have to deal with it anymore. Of course you can combine the keywords in a single JSON document.</p>
<pre><code>Plug &#39;Valloric/YouCompleteMe&#39;, { &#39;do&#39;: &#39;./install.py&#39;, &#39;for&#39;: &#39;cpp&#39; }</code></pre>
<p>Those are the things I mainly use, but there is much more to discover. For a full reference head over to the <a href="https://github.com/junegunn/vim-plug">GitHub page of vim-plug</a>.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>The power of Vim Plugins: CtrlP</title>
    <link href="https://snow-dev.com/posts/the-power-of-vim-plugins-ctrlp.html" />
    <id>https://snow-dev.com/posts/the-power-of-vim-plugins-ctrlp.html</id>
    <published>2016-01-11T00:00:00Z</published>
    <updated>2016-01-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2016-01-11
    </section>
    <hr class="section-head">
    <section>
        <p>In this article we will discover one of the greatest and most widely used plugins in the vim world: CtrlP. It covers a similar area like NERDTree, because it helps you to find and open files very quickly. The magic behind this plugin is it’s fuzzy search engine. You can type in any region of a file path and the fuzzy search matches it to possible files and directory parts. The more matches there are, the higher it is ranked in the results. This means, that you don’t need to type in the beginning of a file path, but it can be any arbitrary part of the path. Of course you want to type in those parts that make a file unique to match it as fast as possible. With some practice it is a highly efficient way of navigate to files. Of course NERDTree and other tree views have their right to exist, but CtrlP is far more useful in most situations. In my humble opinion the big hype around this feature started with Textmate. It shipped this feature right with the editor itself. There was no need to install additional stuff to get the fuzzy search. In Textmate the shortcut for this feature was <em>Ctrl-P</em>. So this is why the corresponding vim plugin has the name CtrlP. But there is no official statements in the docs about it. In the process many other editors adopted this feature in form of a built-in feature (atom) or in form of a plugin (emacs[helm]). Most search requests still give you kien’s CtrlP GitHub Repository. Sad news is he isn’t actively maintaining it anymore. Good news is there is an active <a href="https://github.com/ctrlpvim/ctrlp.vim">fork</a> where you should download it from. After installing CtrlP, you should be able to call it with :CtrlP. A new horizontal split view should have opened at the bottom now.</p>
<p><img src="/images/ctrlp.png" alt="CtrlP" title="CtrlP" /></p>
<p>If you type in some letters the result list should get modified. Also the parts of the file paths are highlighted, which match your typed in string. If you press <em><esc></em> the split will be closed again. Like always, we don’t want to type in the whole command over and over again if we want to execute CtrlP. So let’s configure a proper shortcut for opening CtrlP.</p>
<pre><code>let g:ctrlp_map = &#39;&lt;C-p&gt;&#39; 
let g:ctrlp_cmd = &#39;CtrlP&#39;</code></pre>
<p>What a surprise! We mapped CtrlP to <em><C-p\></em>. Now you should be able to open CtrlP much faster. Maybe you recognized it during the first test already: the CtrlP split isn’t modal. If you try to go into normal mode, to navigate through the results, the CtrlP view closes immediately. But this doesn’t mean, that you need to blow the dust from your arrow keys. You can still navigate up and down with <strong>j</strong> and <strong>k</strong> by holding down <strong>Ctrl</strong> at the same time. You are also not bound to to the enter key, when opening files, even though this is the fastest way to open a file in the current buffer. If you try to open a file with <em><C-o\></em> you have the chance to choose how you want to open it. You can choose between [t]ab, [h]orizontal, [v]ertical and [r]eplace. The first letter stands for the key, which needs to be pressed to apply the command. Replace doesn’t make much sense in my opinion, because pressing Enter(<CR\>) is much faster. Of course there are shortcuts for the other kinds of opening as well. <em><C-t\></em> opens the file in a new tab, <em><C-v\></em> opens it in a vertical split and <em><C-x\></em> does the job in a horizontal split.</p>
<h1 id="modes">Modes</h1>
<p>In the previous chapter we learned about the basic navigation features, but there is much more to explore. If we open CtrlP we see the whole path for each file. This is the filepath mode. In addition to this mode there are three other ones. Let’s call them: <em>major modes</em>. There is a buffer mode, which shows a list of all open buffers of our current Vim session. The third mode is called MRU(most recently used) files. The name says it all. You are able to cycle through these modes by pressing <em><C-f\></em> (forward) or <em><C-b\></em> (backward).</p>
<p><img src="/images/ctrlp-buffers.png" alt="CtrlP Buffers" title="CtrlP Buffers" /></p>
<p>The highlighted mode is always the active mode, as you can see in the image. In this case we are in the buffer mode. If you cycle back with <em><C-b\></em> you would access the file mode and CtrlP would look like this</p>
<p><img src="/images/ctrlp-files.png" alt="CtrlP Files" title="CtrlP Files" /></p>
<p>As you can see now, files is the highlighted mode. On the right is the buffer mode, in which we were in before. You can access it again by pressing &lt;<em>C-f&gt;.</em> So you can imagine the modes as a merry-go-round. The mode on the right is always accessed by cycling forward and the mode on the left of the current mode is accessed by cycling back. Thanks to thomass for putting this right in the comments section. I’m using the Buffer list very often, so I created an additional shortcut for it like this:</p>
<pre><code>nnoremap &lt;leader&gt;b :CtrlPBuffer&lt;CR&gt;</code></pre>
<p>The same thing can be done for MRU. The command is called <em>:CtrlPMRUFiles</em>. Next to these major modes, there are two additional minor modes which can be turned on or off for every one of these three major modes. These minor modes are also saved for the future. This means, if you close CtrlP and open it up later, those modes are still active. The first is the file only mode, which can be activated by pressing <em><C-d\></em>. If this mode is active your typed in characters are only matched against the filename itself, not the rest of the path. I usually prefer the file only search in smaller projects and path in bigger ones. The reason is, that I can have redundant file names more often and this way I can distinguish better between them by typing in distinct parts of the path. To distinguish between file and path mode, there is a small d at the beginning of the CtrlP prompt, when in file mode.</p>
<p><img src="/images/file_only_mode.png" alt="File Only Mode Image" title="File Only Mode" /></p>
<p>The other minor mode is the regex mode, which is called by pressing <em><C-r\></em>. It’s indicated by a small r at the beginning of the prompt.</p>
<p><img src="/images/regex_mode.png" alt="Regex Mode Image" title="Regex Mode" /></p>
<p>I don’t really use it at all, but I’m sure it’s very helpful in some scenarios. Both of these modes are active until you turn them off by pressing the same key combination again. Additionally both of these minor modes can be active at the same time.</p>
<p><img src="/images/both_modes.png" alt="Both Modes Image" title="Both Modes" /></p>
<h1 id="execute-command-on-open">Execute command on open</h1>
<p>This is also a neat feature. For example, if you got an error message in a program you are currently coding on. It’s telling you the file and line, where it occurred. Now you are able to type in the file name and write a <strong>:</strong> afterwards, followed by the line number and CtrlP opens the file and executes the line command afterwards. This is almost the only command I use, but you can give CtrlP every valid Vim command like <strong>:q</strong>, which opens the file and quits the buffer right afterwards. This doesn’t make sense at all, but it shows, that almost every command is possible.</p>
<h1 id="further-configuration">Further Configuration</h1>
<p>This is already a good chunk of stuff we get from CtrlP. But with some more configuration, we can get even more from it. Maybe you’ve noticed, there are also files listed up, that you don’t want to open ever. There are two ways to ignore those in a CtrlP listing. The first option is, you populate the Vim <em>wildignore</em> setting with the file endings you don’t want to open. These will also be ignored by Vim itself. Furthermore other plugins make use of this setting, too. So if you don’t want to open these filetypes at all in Vim, <em>wildignore</em> is the way to go for you. To add it your <em>.vimrc</em>, you type in the following:</p>
<pre><code>set wildignore += *.swp,*.zip,*.exe,*/tmp/*</code></pre>
<p>There you have a comma separated list with some _*.ending_ definitions. The star says, that any arbitrary name can occur before a dot and the file ending. If you add a slash, this setting is also able to ignore complete directories. For example the last argument in the list ignores all kinds of tmp directories. The 2 stars say, that the tmp directory can lie anywhere in the file system and anything that lies in this tmp folder will be ignored as well. The second way is the CtrlP only way. To ignore specific file types in CtrlP only, you add the following to your <em>.vimrc</em>.</p>
<pre><code>let g:ctrlp_custom_ignore = {
    \ &#39;dir&#39;: &#39;\\v\[\\/\]\\.(git|hg|svn)$&#39;,
    \ &#39;file&#39;: &#39;\\v\\.(exe|so|dll)$&#39;,
\ }</code></pre>
<p>This example is taken from the official documentation. As you can see, this list is separated by directories and files. This snippet would ignore git, hg and svn directories in your project as well as files ending with exe, so and dll. We don’t go into more detail about what the regex notions mean, but if you want to to add or remove anything you can do so by adding them inside the brackets. Be sure to have the pipe between the arguments. One more important configuration is to tell CtrlP where to search for files. Add this to your <em>.vimrc</em></p>
<pre><code>let g:ctrlp_working_path_mode = &#39;ar&#39;</code></pre>
<p>This tells CtrlP where to start the search and where to search. There are some characters with a special meaning, which can be combined to set this configuration. The <strong>a</strong> tells that CtrlP should search in the current directory unless it’s not a sub directory of where vim was called. This normally occurs if you start vim from the console. The <strong>r</strong> flag tells CtrlP that it should iterate through parent directories for files until it finds a Version Control System Directory like the .git or .hg directory. This flag is very useful if you often work on projects, which were checked out from git or another VCS, because they act like a natural delimiter for your project files, which you want to find inside of CtrlP. There are also some more options, which I haven’t set. The <strong>c</strong> option says, that only files of the current directory are listed, <strong>w</strong> is the opposite of <strong>a</strong>. It starts the search from the cwd up to the sub directory of your current file, while <strong>a</strong> does it the other way around. An empty string or <strong>0</strong> would disable this feature completely. This is it. The post was getting longer as I thought initially. But I got one more neat snippet, which you can use to make CtrlP search even faster:</p>
<pre><code>let g:ctrlp_use_caching = 0
if executable(&#39;ag&#39;)
    set grepprg=ag\ --nogroup\ --nocolor

    let g:ctrlp_user_command = &#39;ag %s -l --nocolor -g &quot;&quot;&#39;
else
    let g:ctrlp_user_command = [
        \ &#39;.git&#39;,
        \ &#39;cd %s &amp;&amp; git ls-files . -co --exclude-standard&#39;,
        \ &#39;find %s -type f&#39;
    \ ]
    let g:ctrlp_prompt_mappings = {
    \ &#39;AcceptSelection(&quot;e&quot;)&#39;: [&#39;&lt;space&gt;&#39;, &#39;&lt;cr&gt;&#39;, &#39;&lt;2-LeftMouse&gt;&#39;],
    \ }
endif</code></pre>
<p>I found this on one of my favorite <a href="http://sheerun.net/2014/03/21/how-to-boost-your-vim-productivity/">vim blog posts</a> of all time. To use it, you need to have Ag (a.k.a the silver searcher) installed, which is a tool that can search for patterns in many files and directories. We will come to the Vim Plugin for Ag later. For now you can download Ag with your package manager and enjoy the advantages of this snippet. If you don’t want to install Ag right now, it’s also ok if you have git installed, which you already did, if you followed the first post of this series. Overall the Ag and Git search engines are much faster than the normal grep, which is used by CtrlP. For me it made a big difference in huge projects. This is by far no complete reference about CtrlP. If you need further information you can type the command <em>:h CtrlP</em> into Vim.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>The power of Vim Plugins: netrw</title>
    <link href="https://snow-dev.com/posts/the-power-of-vim-plugins-netrw.html" />
    <id>https://snow-dev.com/posts/the-power-of-vim-plugins-netrw.html</id>
    <published>2015-11-03T00:00:00Z</published>
    <updated>2015-11-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2015-11-03
    </section>
    <hr class="section-head">
    <section>
        <p>This time we look into an alternative for NERDTree, which is called netrw. Thanks to <a href="https://www.reddit.com/user/aguerosantiale">aguerosantiale</a>, who put my attention onto it. Both plugins serve the same purpose, but they behave fundamentaly different in archiving this. So the first question you will probably ask is: “why use netrw, if I’m already familiar with NERDTree?”. The biggest plus for netrw is, that you don’t have to download anything. If you <em>set nocampatible</em> in your .vimrc you are able to use it. So if you are on a different machine, for example connected via ssh, you are able to use netrw. The second point is, that vim is very reactive by nature, but if you have too many plugins running at the same time, you could destroy this attribute. So it’s always good to use something, what is already there. Not everyone will like netrw, because it isn’t the approach you know from Sublime Text or others. Netrw is a so called split explorer, while tree views like NERDTree are called project drawer. To learn about the difference, we will talk about the project drawer approach first. Project drawer open a new split view on the left(sometimes right) and stays opened during your complete coding session. Every time you click on an item in the project drawer, it opens the files in a separate buffer.</p>
<p><img src="/images/blog_explorer.png" alt="Explorer" title="Explorer" /></p>
<p>Vim wasn’t supposed to work along with a feature like this. That’s why we had to do some tweaks in the <a href="http://snow-dev.com/the-power-of-vim-plugins-nerdtree/">last post</a>, to make it work. Especially if you are working with splits, you first must know in which split NERDTree opens your file. If you got that down, you need to learn, how to navigate between them fast. If you want to open a file in a split, which is on the opposite to the project drawer, you have to go a long way… That’s why we created a keybinding to toggle NERDTree instantly. Then we choose a file and got thrown in the opened buffer immediately. To sum it up: that aren’t d many key presses to get work done with NERDTree. So overall they provide a very good solution for bringin in a principle, which wasn’t supposed to be in vim initially. But what is different with the split explorer? A split explorer opens up in the same buffer. You then are able to choose a new file and this file opens up in the same buffer again. It’s like sitting in front of a book and having the table of contents opened. You look up the page you want to see and switch to the according page. If you read the page, you can go back to the table of contents and choose a new page and switch to it and so on and so forth. You are also able to open the explorer in another split view and choose which file to open from there.</p>
<p><img src="/images/split.png" alt="Split" title="Split" /></p>
<p>So what’s the benefit from this? First of all: you look at the project drawer very rarely(only if you want to change a file). So let’s say 5% of your time coding is spent with the project explorer and the rest of the time you ignore it. But 95% of the time it is still open and takes away space from your monitor. So why not keep it closed as long as you are working on a file until you need to switch? Another benefit is, that you always know where your buffer opens up. If you want to know more about project drawers and split explorers, have a look at <a href="http://vimcasts.org/blog/2013/01/oil-and-vinegar-split-windows-and-project-drawer/">oil and vinegar</a>, it’s great in-depth article about this topic. If you are a NERDTree user and you are critical with the previous principle, you can test the split explorer by adding the following line to your .vimrc</p>
<pre><code>let NERDTreeHijackNetrw=1</code></pre>
<p>Close your normal NERDTree with the <em>:NERDTreeToggle</em> command and type in <em>:e .</em> or create a mapping in your .vimrc. This is mine for example:</p>
<pre><code>nnoremap &lt;leader&gt;e :e .&lt;CR&gt;</code></pre>
<p>Of course you can take whatever binding you are comfortable with. Now NERDTree should be opened in the buffer you are currently in and if you open a file, NERDTree will hide and your chosen file appears instead. You can experiment with this setup now. If you feel more comfortable with this setup, like me, you can also do the switch to netrw. You need to learn some new shortcuts for netrw, but they are pretty intuitive in my opinion. If you don’t want to go that way, you can stay with this NERDTree approach aswell and if you don’t feel comfortable with the split explorer approach at all you can keep using NERDTree as it is. If you decided for netrw, I will get you going in the upcoming couple of paragraphs.</p>
<h2 id="configuration">Configuration</h2>
<p>If you removed NERDTree and all the according configuration from your .vimrc you can add the following line to your .vimrc.</p>
<pre><code>let g:netrw_liststyle=3</code></pre>
<p>This will open up netrw in tree like view and not a list. So it’s easier to recognize which are contents of which subfolders. You can now press the shortcut defined above and you should see netrw. You are also able to open up netrw in a vertical or horizontal split. I’ve created the following keybindings:</p>
<pre><code>&quot;Open netrw in a vertical split
nnoremap &lt;Leader&gt;v :vs .&lt;CR&gt;
&quot;Open netrw in a horizontal split
nnoremap &lt;Leader&gt;s :sp .&lt;CR&gt;</code></pre>
<p>I use these, when I want to compare two files or look something up from another file. The banner at the top is pretty helpful in the beginning, but it only took away space when I knew all the information. At this point I added the following to my .vimrc</p>
<pre><code>let g:netrw_banner=0</code></pre>
<p>This will hide the banner and only shows the tree itself.</p>
<h2 id="navigation">Navigation</h2>
<p>Like in NERDTree, you are able to navigate with the <em>j</em> and <em>k</em> keys. You can go to the top with <em>gg</em> and to the bottom with <em>G</em>. You are also able to search in the explorer buffer, to get to a specific entry fast(Those options are also available in NERDTree, but I didn’t mentioned them in the last post). But jump up and down a directory(NERDTree: <em>p</em> and <em>P</em>) don’t exist from what I’ve found out so far. Files and folders are opened by pressing <em><CR></em>(Enter).</p>
<h2 id="bookmarking">Bookmarking</h2>
<p>You are able to bookmark directories, but no files. By pressing <em>mb</em> you create a bookmark. With <em>qb</em> you can open a quick fix window, which shows the history and bookmarked directories, but you aren’t able to choose anything here. With <em>gb</em> you should be able to jump to the last bookmark. Bookmarking and everything project related, like changing the current work directory and minimizing the tree to the current directory are the biggest downside with netrw, because they often seem to not work properly or are missing completely.</p>
<h2 id="opening-files">Opening files</h2>
<p>Like already mentioned, files can be opened by pressing <em><CR></em>(Enter). Then they open up in the same view. You can also use <em>o</em> to open a file in a horizontal split or <em>v</em> to open in a vertical split. Additionally we’ve set shortcuts in the beginning to open up a split explorer in another split.</p>
<h2 id="modifying-nodes-in-the-file-system">Modifying Nodes in the file system</h2>
<p>In NERDTree we needed to call a menu first and choose our operation afterwards, but in netrw there is a keybinding for each of these operations, without the need to open a menu first. New files can be created by pressing <em>%</em>. You need to type in the name afterwards and the file will be opened automatically. By pressing <em>d</em> you create a new directory. <em>D</em> deletes the current node under your cursor, whatever it is a directory or file. The last operation in this bulk is renaming, which is called with <em>R</em>. All operations will be done relative from your current cursor position. But also this has a downside. Creating new files don’t show up immediately. Sometimes even a refresh didn’t help(<em>C-l</em>). So I had to close the sub directory and open it again, until it showed up.</p>
<h2 id="summary">Summary</h2>
<p>I really like the split explorer approach, but for me netrw shows his weaknesses, if I want to do anything advanced. I think netrw is the perfect choice, if you only rely on navigation and opening files. If you want to do more, netrw falters. NERDTree also isn’t perfect to use with this approach, because every time it is opened, it is reset. This means that every opened directory is closed. So you have to navigate the whole way to a file again. Thats why NERDTree is only a good choice, if you want to stay with the project drawer approach. If you decided to stay with netrw and need further help, you can type in</p>
<pre><code>:h netrw</code></pre>
<p>This will show you the whole documentation of netrw, containing all it’s features and configuration possibilities. During the writing of this article I also am experimenting with vimfiler, which seems to combine the good things of both plugins and adds a whole bunch of configuration possibilities on top of it. I will probably cover this plugin in a later post, if it fulfills my needs.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>The power of Vim Plugins: NERDTree</title>
    <link href="https://snow-dev.com/posts/the-power-of-vim-plugins-nerdtree.html" />
    <id>https://snow-dev.com/posts/the-power-of-vim-plugins-nerdtree.html</id>
    <published>2015-10-16T00:00:00Z</published>
    <updated>2015-10-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2015-10-16
    </section>
    <hr class="section-head">
    <section>
        <p>Hey everyone, this time we will cover a plugin called <a href="https://github.com/scrooloose/nerdtree">NERDTree</a>. This is the kind of addition, which shows the file system with all it’s files and sub folders. It is a great tool to keep an overview, when working on a project or a big set of files. Because I’m coming from a Sublime background, it was one of the first things I’ve been missing. I was and am still one of those people, who interact with the tree view quite a lot. I also prefer it over tabs and other alternatives, but that is just my personal preference. With <a href="https://github.com/VundleVim/Vundle.vim">Vundle</a> installed from the last <a href="http://snow-dev.com/the-power-of-vim-plugins-vundle/">post</a>, it is pretty easy to get started with NERDTree. Just add the following line to your plugin list inside your <em>.vimrc</em></p>
<pre class="vim"><code>Plugin &#39;scrooloose/nerdtree&#39;</code></pre>
<p>Re-source your <em>.vimrc</em> and call <em>:PluginInstall</em>. Restart vim, just to be save everything is properly set. Now call <em>:NERDTreeToggle</em> and the tree view should pop up on the left side of your vim instance.</p>
<p><img src="/images/nerdtree.png" alt="NerdTree" title="NerdTree" /></p>
<p>NERDTree is just another split view, in which you aren’t able to write anything. It has it’s own shortcuts, to which we come later.</p>
<h1 id="configuration">Configuration</h1>
<p>The first thing you probably think of, is why would I call <em>:NERDTreeToggle</em> every time I start vim or open a new buffer. To end this struggle, just add the following line into your <em>.vimrc</em></p>
<pre class="vim"><code>autocmd VimEnter * NERDTree</code></pre>
<p>There is one more thing I’m not comfortable with as well. And this is the cursor being in NERDTree after startup. To position the cursor in the code file to the right of NERDTree at the beginning, add the following line to the <em>.vimrc</em></p>
<pre class="vim"><code>autocmd VimEnter * wincmd p</code></pre>
<p>If you are working with tabs on a regular basis, you will encounter, that NERDTree isn’t opened in new tabs as well. To mirror our existing NERDTree to other tabs, we need an additional command in our <em>.vimrc</em></p>
<pre><code>autocmd BufWinEnter * NERDTreeMirror</code></pre>
<p>An alternative approach is the <a href="https://github.com/jistr/vim-nerdtree-tabs">NERDTree-Tabs</a> plugin, which enables this feature by default, without any configuration effort. The last thing I have configured is a shortcut to focus NERDTree. Because I’m working with split views pretty much at the moment, it is very inconvenient to walk through all the views, until I’m back into NERDTree.</p>
<pre class="vim"><code>map &lt;F5&gt; :NERDTreeFocus&lt;CR&gt;</code></pre>
<p>This maps the control key <strong>F5</strong> to the NERDTree focus action. If you prefer another key or a combination you are free to use whatever you are comfortable with.</p>
<h1 id="usage">Usage</h1>
<p>With the last part of the configuration, we already stepped into the usage. But what are we able to do, if we called <em>:NERDTreeFocus</em>? The short answer is: pretty much everything you can do with a tree view in Sublime and other editors/IDEs. In this tutorial I only go through the functions I use mostly, but there are plenty more helpful shortcuts and functionalities. For a full reference you can always type in ? while in NERDTree and you get the full list of shortcuts. Press ? again to come back to the tree view. # Navigation Ok, lets start of easy. <strong>j</strong> and <strong>k</strong> are also used for navigating up and down like in any other buffer. To jump to the parent directory, you can press <strong>p</strong> and if you want to go to your root directory you press <strong>P</strong>. To open a directory press <strong>o</strong>. This will show all files and sub directories. To close the directory, simply press <strong>o</strong> again. # Setting the current node and bookmark The number one reason we want to use NERDTree is an overview of our current project or set of files, which is always a sub node in our file system. At the moment I’m navigating through the console to the root directory of my project and open vim there. But there is also a NERDTree way of doing this. You navigate to the root directory of your project in NERDTRee and press <strong>cd</strong> afterwards. This means “change directory” and it doesn’t have any visual effect. But now every command you type into command-line mode is relative to your chosen root directory and not to the system root. Next thing you may want to do is to only show this directory and hide the rest of your file system. By pressing <strong>C</strong> you set the underlying directory as the top most visible node. Every time you want to work on your project you need to navigate there. This gets very exhaustive, but NERDTree has a neat feature called bookmarks. You can bookmark directories and files and you are instantly able to open them from a bookmarks list, without navigating there first. To bookmark a node, like our project root, we type in <em>:Bookmark</em>, while NERDTree is focused and the project root is chosen. To open our bookmarks we can press <strong>B</strong> and now we can type <strong>cd</strong>, <strong>C</strong> and <strong>o</strong> on the chosen bookmark and we are in our project without navigating there first.</p>
<p><img src="/images/nerdtree_bookmarks.png" alt="NerdTree Bookmarks" title="NerdTree Bookmarks" /></p>
<p>If you want to get rid of the bookmark, you just navigate to the bookmark and press <strong>D</strong>.</p>
<h1 id="opening-files">Opening files</h1>
<p>Now we come to the most important part, actually opening a file. There are many different ways of opening. A normal open in the buffer to the right is done by pressing <strong>o</strong>. But you are also able to open a file in a new tab[<strong>t</strong>], in a vertical split[<strong>s</strong>] or horizontal split[<strong>i</strong>]. As a site node: <strong>o</strong> is always overwriting the buffer you were in last. So for example, if you opened some vertical splits and you are in the most right split, you focus NERDTree and open another file by pressing <strong>o</strong>, the most right buffer will be overwritten.</p>
<h1 id="modifying-nodes-in-the-file-system">Modifying nodes in the file system</h1>
<p>In the beginning I just used terminal commands like <em>touch/mkdir/mv</em>. With the help of <strong>:!</strong> I was able to do any CLI command from within vim. Afterwards I needed to refresh the file system by pressing <strong>R</strong>. But I discovered a much easier way of doing things like these, quite recently. Just go to a node, which you want to modify and press <strong>m</strong>. Now you get an overview of allowed operations.</p>
<p><img src="/images/nerdtree_menu.png" alt="NERDTree Menu" title="NERDTree Menu" /></p>
<p>These are adding, moving/renaming, copying and removing files or directories. Just choose the shortcut in front of the option and you will be put to the next instruction buffer. Removing needs to be confirmed by a ‘yes’. Adding, moving and copying requires the new path. As an example: if you want to add a new directory you press <strong>m</strong> on the given node, followed by <strong>a</strong> and then type in a directory name, followed by a <strong>/</strong>, otherwise a file would be created. If you are ok with the name, you confirm by pressing <strong>Enter</strong>. Every modification done from this menu will update your tree view automatically, so there is no need to refresh manually. I hope, this overview will get you started with NERDTree properly. If you have any questions you can ask them in the comment section below.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>A basic Routing approach with PHP</title>
    <link href="https://snow-dev.com/posts/how-modern-routing-works-in-php.html" />
    <id>https://snow-dev.com/posts/how-modern-routing-works-in-php.html</id>
    <published>2015-10-07T00:00:00Z</published>
    <updated>2015-10-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2015-10-07
    </section>
    <hr class="section-head">
    <section>
        <p>Nice and readable URLs are the way to go in modern web applications. More and more people are abandoning the old style URLs, containing question marks and  equal signs, in favor of the slash separation for actions and parameters. Most frameworks are already supporting this new kind of URLs and encapsulate the logic inside of a routing class or module. Everyone is using it and everything is good so far. But even if these new URLs are all over the place, there is very little information on the net about how it is actually implemented. Because I’m currently working on a minimalistic PHP MVC Framework with a <a href="http://randy-schuett.de">friend</a>, I came across this problem. Beside of the source code of the big players in PHP Frameworks I found a small and easy to use snippet to get routes working pretty fast. In this post I want to present the key PHP feature, which allows us to realize it and how to build upon it. Everything starts of with the PHP super constant <a href="http://php.net/manual/en/reserved.variables.server.php">$_SERVER</a>. We are interested about the ‘REQUEST_URI’  key. If we type in the address of our webserver, followed by and <em>/index.php</em> and this file contains the following line of code.</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php"><span class="kw">&lt;?php</span>
<span class="fu">echo</span> <span class="kw">$_SERVER</span><span class="ot">[</span><span class="st">&#39;REQUEST_URI&#39;</span><span class="ot">];</span></code></pre></div>
<p>we probably would get back <em>/index.php</em>. This is exactly what we wanted to archive, because now we are able to read what the user typed into the address bar of his browser and now we can react to it. But with this approach comes a problem. If we would build our Router upon this feature, we are forced to place a file at each possible path, which we want to cover, containing the request of the super constant and reroute to the appropriate controller and action. A good way to solve this problem would be, that whatever the user types into the address bar, it would open up the same file everytime, like our <em>index.php</em>. Sadly there is no way to solve this in PHP. So this has to be done on the webserver level itself. Most webservers (like Apache)  support configurations written down to a <em>.htaccess</em> file, which is placed in the root directory of the webserver. We write the following content to the file.</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php">RewriteEngine On
RewriteRule ^<span class="ot">(</span>.*<span class="ot">)</span> - <span class="ot">[</span><span class="kw">E</span>=<span class="kw">BASE</span>:%<span class="dv">1</span><span class="ot">]</span>
RewriteRule ^<span class="ot">(</span>.*<span class="ot">)</span>$ %{<span class="kw">ENV</span>:<span class="kw">BASE</span>}index.php <span class="ot">[</span><span class="kw">NC</span><span class="ot">,</span><span class="kw">L</span><span class="ot">]</span></code></pre></div>
<p>The first directive tells the webserver to turn on the rewrite engine. Afterwards we give him the rules to link everything to the <em>index.php</em> in the root directory. Now we can type in <em>/test/dir/index</em> for example and the <em>index.php</em> in the root directory is called, but with this output instead: <em>/test/dir/index</em>. Based on this behavior we can build our Router. For a minimalistic example we create a <em>Router.php</em> file which contains the following class.</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php"><span class="kw">&lt;?php</span>

<span class="kw">class</span> Router
{
    <span class="kw">public</span> <span class="kw">function</span> route<span class="ot">(</span><span class="kw">$route</span><span class="ot">)</span>
    {
        <span class="fu">echo</span> <span class="kw">$route</span><span class="ot">;</span>
    }
}</code></pre></div>
<p>and we change our <em>index.php</em>.</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php"><span class="kw">&lt;?php</span>

<span class="kw">require_once</span> <span class="st">&#39;Router.php&#39;</span><span class="ot">;</span>

<span class="kw">$r</span> = <span class="kw">new</span> Router<span class="ot">();</span>
<span class="kw">$r</span>-&gt;route<span class="ot">(</span><span class="kw">$_SERVER</span><span class="ot">[</span><span class="st">&#39;REQUEST_URI&#39;</span><span class="ot">]);</span></code></pre></div>
<p>So far we gained nothing except a new layer of abstraction. But now we are able to actually give our routing some behavior, similar to modern frameworks, which are based on controllers and actions. As an example we take the following path <em>/default/print_hello</em>. In theory this should instantiate a <em>DefaultController</em> class and call the <em>print_helloAction</em> method. As a place for our controllers we create a new directory called <em>controllers</em> and add a <em>DefaultController.php</em> file.</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php"><span class="kw">&lt;?php</span>

<span class="kw">class</span> DefaultController
{
    <span class="kw">public</span> <span class="kw">function</span> indexAction<span class="ot">()</span>
    {
        <span class="fu">echo</span> <span class="st">&#39;Index&#39;</span><span class="ot">;</span>
    }

    <span class="kw">public</span> <span class="kw">function</span> print_helloAction<span class="ot">()</span>
    {
        <span class="fu">echo</span> <span class="st">&#39;Hello&#39;</span><span class="ot">;</span>
    }
}</code></pre></div>
<p>The last part of this post will be about how our Router class can actually instantiate the <em>DefaultController</em> and call the method based on the given route. One way to do it is to cut down the string at the slashes. Afterwards we got the controller and action name which we are now able to instantiate and call. The code for the route function could look like this.</p>
<div class="sourceCode"><pre class="sourceCode php"><code class="sourceCode php"><span class="kw">&lt;?php</span>

<span class="kw">class</span> Router
{
    <span class="kw">public</span> <span class="kw">function</span> route<span class="ot">(</span><span class="kw">$route</span><span class="ot">)</span>
    {
        <span class="kw">$parts</span> = <span class="fu">explode</span><span class="ot">(</span><span class="st">&#39;/&#39;</span><span class="ot">,</span> <span class="kw">$route</span><span class="ot">);</span>
        <span class="co">//Index 0 is empty because the routes</span>
        <span class="co">//always start with a preceding /</span>
        <span class="kw">$controller</span> = <span class="fu">array_key_exists</span><span class="ot">(</span><span class="dv">1</span><span class="ot">,</span> <span class="kw">$parts</span><span class="ot">)</span> <span class="ot">?</span> <span class="kw">$parts</span><span class="ot">[</span><span class="dv">1</span><span class="ot">]</span> <span class="ot">:</span> <span class="st">&#39;&#39;</span><span class="ot">;</span>
        <span class="kw">$action</span>     = <span class="fu">array_key_exists</span><span class="ot">(</span><span class="dv">2</span><span class="ot">,</span> <span class="kw">$parts</span><span class="ot">)</span> <span class="ot">?</span> <span class="kw">$parts</span><span class="ot">[</span><span class="dv">2</span><span class="ot">]</span> <span class="ot">:</span> <span class="st">&#39;&#39;</span><span class="ot">;</span>

        <span class="kw">if</span> <span class="ot">(</span><span class="fu">strlen</span><span class="ot">(</span><span class="kw">$controller</span><span class="ot">))</span> {
            <span class="co">//upper case the first letter of the controller name and</span>
            <span class="co">//append the Controller string to it</span>
            <span class="kw">$controller</span> = <span class="fu">ucfirst</span><span class="ot">(</span><span class="kw">$controller</span><span class="ot">)</span> . <span class="st">&#39;Controller&#39;</span><span class="ot">;</span>
            <span class="co">//Include the PHP file for the Controller</span>
            <span class="kw">require_once</span> <span class="st">&#39;controllers/&#39;</span> . <span class="kw">$controller</span> . <span class="st">&#39;.php&#39;</span><span class="ot">;</span>
            <span class="co">//instantiate the controller</span>
            <span class="kw">$object</span> = <span class="kw">new</span> <span class="kw">$controller</span><span class="ot">;</span>
            <span class="co">//call the action</span>
            <span class="kw">if</span> <span class="ot">(</span><span class="fu">strlen</span><span class="ot">(</span><span class="kw">$action</span><span class="ot">))</span> {
                <span class="kw">return</span> <span class="fu">call_user_func</span><span class="ot">([</span><span class="kw">$object</span><span class="ot">,</span> <span class="kw">$action</span> . <span class="st">&#39;Action&#39;</span><span class="ot">]);</span>
            }
            <span class="co">//call indexAction if no action is given</span>
            <span class="kw">return</span> <span class="fu">call_user_func</span><span class="ot">([</span><span class="kw">$object</span><span class="ot">,</span> <span class="st">&#39;indexAction&#39;</span><span class="ot">]);</span>
        }
    }
}</code></pre></div>
<p>If we type in <em>/default/print_hello</em> we get back <em>Hello</em>. If no action is given, we automatically try to route to the index action. So <em>/default</em> would print <em>Index</em>. <a href="http://php.net/manual/en/function.call-user-func.php">call_user_func</a> also supports parameters. So it is very easy to extend the given Router with parameter handling. Also there should be more handling of special cases, like if no controller is given in the URL. It’s also simple to extend the given model to use real view files for showing a page, instead of just doing an echo. Nevertheless serves this basic concept  as a starting point and it should be straightforward to build upon it.</p>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>The power of Vim Plugins: Vundle</title>
    <link href="https://snow-dev.com/posts/the-power-of-vim-plugins-vundle.html" />
    <id>https://snow-dev.com/posts/the-power-of-vim-plugins-vundle.html</id>
    <published>2015-09-29T00:00:00Z</published>
    <updated>2015-09-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2015-09-29
    </section>
    <hr class="section-head">
    <section>
        <p>To start of this series properly, we need a plugin manager, to handle all our plugins and keep them up to date. <a href="https://github.com/VundleVim/Vundle.vim">Vundle</a> is one common option, but there are some more to choose from. Two more big players in this business are <a href="https://github.com/Shougo/neobundle.vim">NeoBundle</a> and <a href="https://github.com/tpope/vim-pathogen">Pathogen</a>. I didn’t looked too deep into the last two plugin managers. To be honest, I never tried out something else than Vundle and I think the reason is that I never felt uncomfortable or missed something. So I never felt in need of getting another plugin manager and in this post I want to show you why. First of all you need to have git installed. You can download git with the package manager of your distribution, if it isn’t installed already. You can easily check this by starting up your console and type in the following:</p>
<pre><code>git --version </code></pre>
<p>If git version &lt;some number&gt; appears you are good to go, but if something like unknown command pops up, you are in a lot of trouble… Not really. You just need to install git with your package manager and everything will be fine. For the most common Linux distributions, the command looks like one of these:</p>
<pre><code>apt-get install git</code></pre>
<pre><code>yum install git</code></pre>
<pre><code>pacman -S git</code></pre>
<p>When git is installed you download Vundle by executing the following command in your console:</p>
<pre><code>git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</code></pre>
<p>This command downloads the Vundle code into bundle in your personal vim directory. The bundle directory will be the place where all your plugins are saved. If you’re done, you should keep git on your computer, because vundle is working with git commands internally. If it doesn’t find git, you aren’t able to use Vundle at all. Now we need to add some stuff to the .vimrc. The .vimrc is a file, where all your configurations in relation to Vim are placed. If you didn’t edit anything there yet, have a look at your home directory (Make sure to also show invisible files). If there is no such file, you can create it now and it will be automatically loaded, when vim is starting the next time. Now we need to initialize Vundle. To do so we place a code snippet at the beginning of the .vimrc(It is very important to place the following snippet in front of your existing configuration, if you already have written down some configurations).</p>
<pre class="viml"><code>set nocompatible              &quot; be iMproved, required
filetype off                  &quot; required

&quot; set the runtime path to include Vundle and initialize
set rtp+=~/.vim/bundle/Vundle.vim
call vundle#begin()

&quot; let Vundle manage Vundle, required

Plugin &#39;VundleVim/Vundle.vim&#39;
&quot;New plugins go here

call vundle#end()</code></pre>
<p>To test if Vundle is working, we add a new plugin. As an example we install NERDTree, which will be covered in the next post of this series. Under the comment _“New plugins go here_ the plugin will be added. Because it is hosted on GitHub we can write the following into the .vimrc</p>
<pre><code>Plugin &#39;scrooloose/nerdtree&#39;</code></pre>
<p>To take this change into effect, you either need to restart Vim or re-source your .vimrc. I’ve got the following line saved into my .vimrc, which automatically re-sources my .vimrc everytime it is saved.</p>
<pre><code>autocmd! bufwritepost .vimrc source %</code></pre>
<p>After restarting/resourcing the .vimrc you enter the following command</p>
<pre><code>:PluginInstall</code></pre>
<p>A new split view is opened, which shows your plugins and either a dot or a star in front. The dot says that nothing was done, because the plugin is already installed and the star says that the new plugin was successfully installed. If anything goes wrong, you get the possibility to open up the log and look up the error. To remove a plugin, you need to remove the corresponding line out of your .vimrc. For example if we want to get rid of the NERDTree Plugin we remove the line, which we just added and save the .vimrc (Don’t forget to re-source/restart). Afterwards type in the following command into Vim:</p>
<pre><code>:PluginClean</code></pre>
<p>A new split view opens with the plugins which will be removed. You can accept it by typing <em>y</em> or abort by typing <em>n. </em> The final command I use on a regular basis is to update my existing plugins.</p>
<pre><code>:PluginUpdate</code></pre>
<p>Again a new split view opens and an arrow is moving through your installed plugins and marks them with a dot or a star, similar to the <em>:PluginInstall</em> command. The symbols also have the same meaning. Dots say that nothing needed to be done and the star tells you if a update was available and installed. If you want to search for new plugins you can use the <em>:PluginSearch</em> command like this:</p>
<pre><code>:PluginSearch nerdtree</code></pre>
<p>But I often got problems doing it this way. So the normal way I search for new plugins is using my search engine of trust. I also prefer downloading every plugin from Github to keep this clean overview of <em>Plugin ‘creator/plugin_name’</em> in my .vimrc. But maybe a plugin isn’t available on GitHub(which was never the case for me), the second best source would be <a href="http://vim-scripts.org">Vim Scripts</a>. To add a Vim Scripts link, you just need to add the name of the plugin, which is even cleaner:</p>
<pre><code>Plugin &#39;nerdtree&#39;</code></pre>
<p>Another option is to include a plugin from a non GitHub Hoster, who also uses git, like Bitbucket. To add a plugin you need to start writing _git: _followed by the complete URL of the plugin. As an imaginary example, if NERDTree would be hosted on Bitbucket, it would look like this:</p>
<pre><code>Plugin &#39;git:bitbucket.com/scrooloose/nerdtree&#39;</code></pre>
<p>I hope I could help with this brief overview of Vundle. If you need further information either head to the GitHub page of the <a href="https://github.com/VundleVim/Vundle.vim">Vundle project</a> or type the following command into Vim:</p>
<pre><code>:h vundle</code></pre>
    </section>
</article>
]]></summary>
</entry>
<entry>
    <title>The power of Vim Plugins</title>
    <link href="https://snow-dev.com/posts/the-power-of-vim-plugins.html" />
    <id>https://snow-dev.com/posts/the-power-of-vim-plugins.html</id>
    <published>2015-09-16T00:00:00Z</published>
    <updated>2015-09-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <section class="header">
        Posted on 2015-09-16
    </section>
    <hr class="section-head">
    <section>
        <p>In this post I want to introduce a new series, which will cover some of the most useful Vim plugins available. There are many guides and tutorials out there about how Vim works and how great its modal editing is. So I won’t cover these things in this series. I personally learned a lot from the book <a href="http://vimcasts.org/publications/">Practical Vim</a> by Drew Neil. He also published a lot of video tutorials, called <a href="http://vimcasts.org/">VimCasts</a>. Before I started of with Vim, I was using Sublime Text and as I started using Vim, I missed some essential knowledge about how to install, configure and use plugins. Part of the problem was, that everyone is telling you: “When you start of with Vim, learn it without any plugins first, so you get used to the modal editing.” Well this isn’t completely correct, because those are two different pairs of shoes. Of course it’s more to learn at once, but many people don’t want to learn Vim completely and then start installing plugins until they find out, that something they need very bad, isn’t available in Vim. So they wasted about 2 months of their life until they can go on with the next tool on their list. Luckily there is not much missing, to transform Vim into a good programming tool, in my opinion. For me it became my one and only code editing/writing tool for work, studying and hobby projects. By configuring plugins, people will discover another great thing: the .vimrc. It’s a file where all the plugins are linked and where Vim is configured, to really become your personal editor. And because it’s just one file, it’s easy to put into a Version Control System like GIT. This gives you the ability to have the same look and feel of Vim on different machines in no time. It’s also the first time you get in touch with VimL(VimScript). It’s a script language, which is used to configure, write plugins and interact with Vim in command mode. So it can be seen the same way as Python for Sublime and Coffeescript for Atom. To give you a slight overview about what is coming next, I will list up a short summary(non-chronologically) of what I want to cover in the next posts.</p>
<ul>
<li>Vundle(The plugin manager of Vim)</li>
<li>NERDTree(A tree like view, which shows the hierarchy of files and sub folders)</li>
<li> CtrlP(A fuzzy search for files. Similar to Sublimes/Atoms Ctrl-P)</li>
<li>YouCompleteMe(A heavy auto completion engine)</li>
<li>VimAirline(A status bar which contains all the important infos about a file)</li>
<li>Themes(This will be more of a general topic about how to install and use themes)</li>
<li>Tagbar(A Symbol View like list for code files)</li>
<li>UltiSnips(Snippets for Vim)</li>
<li>Ag(A project wide search for pieces of texts)</li>
</ul>
    </section>
</article>
]]></summary>
</entry>

</feed>
